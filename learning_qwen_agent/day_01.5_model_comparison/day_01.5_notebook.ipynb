{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Day 1.5: Qwen3 Model Comparison - Complete Guide\n",
    "\n",
    "## üéØ Choosing the Right Model for Your Task\n",
    "\n",
    "### What You'll Learn:\n",
    "1. **Model Variants** - Understanding Thinking vs Instruct vs Coder\n",
    "2. **Real Performance Tests** - Actual API calls with timing and results\n",
    "3. **Feature Comparison** - Context length, pricing, capabilities\n",
    "4. **Use Case Guide** - Which model for which task\n",
    "5. **Hands-on Testing** - Run comparisons yourself\n",
    "\n",
    "### Why This Matters:\n",
    "- ‚è±Ô∏è **Save Time** - Use the fastest model for simple tasks\n",
    "- üí∞ **Save Money** - Don't overpay for capabilities you don't need\n",
    "- ‚úÖ **Better Results** - Match model strengths to your task\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-overview",
   "metadata": {},
   "source": [
    "## Part 1: The Qwen3 Model Family\n",
    "\n",
    "### Available Models on Fireworks AI:\n",
    "\n",
    "| Model | Size | Context | Price (per 1M tokens) | Key Feature |\n",
    "|-------|------|---------|----------------------|-------------|\n",
    "| **Qwen3-235B-A22B-Thinking-2507** | 235B (22B active) | 256K | $0.22 / $0.88 | Shows reasoning process |\n",
    "| **Qwen3-235B-A22B-Instruct-2507** | 235B (22B active) | 256K | $0.22 / $0.88 | Best tool use & speed |\n",
    "| **Qwen3-Coder-480B-A35B-Instruct** | 480B (35B active) | 256K (1M with extrapolation) | $0.45 / $1.80 | Agentic coding specialist |\n",
    "| **Qwen3-235B-A22B** (base) | 235B (22B active) | 16K only | $0.22 / $0.88 | Original, limited context |\n",
    "\n",
    "### Key Differences Explained:\n",
    "\n",
    "#### üß† **Thinking vs Instruct** (Same 235B Model, Different Modes)\n",
    "\n",
    "**Thinking 2507:**\n",
    "- Always in \"thinking mode\"\n",
    "- Shows internal reasoning process\n",
    "- Best for: Complex logic, math, science, reasoning tasks\n",
    "- Takes slightly longer (shows thinking)\n",
    "- Temperature: 0.6, top_p: 0.95\n",
    "\n",
    "**Instruct 2507:**\n",
    "- \"Non-thinking mode\" only\n",
    "- Direct answers without reasoning process\n",
    "- Best for: Tool use, function calling, general tasks\n",
    "- Faster responses\n",
    "- Better instruction following\n",
    "- Temperature: 0.7, top_p: 0.8\n",
    "\n",
    "#### üíª **Coder 480B** (Specialized for Development)\n",
    "\n",
    "- Mixture-of-Experts (480B total, 35B active)\n",
    "- State-of-the-art agentic coding\n",
    "- Excellent tool calling\n",
    "- Repository-scale understanding\n",
    "- 256K native, 1M with extrapolation\n",
    "- 2x cost but specialized capabilities\n",
    "\n",
    "#### üì¶ **Base 235B** (Original Release)\n",
    "\n",
    "- Only 16K context (much smaller!)\n",
    "- Can switch between thinking/non-thinking\n",
    "- Less optimized than 2507 versions\n",
    "- Not recommended (use 2507 versions instead)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Part 2: Setup\n",
    "\n",
    "Same API configuration from Day 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv('/home/user/Qwen-Agent/.env')\n",
    "api_key = os.getenv('FIREWORKS_API_KEY')\n",
    "\n",
    "if api_key:\n",
    "    print(f\"‚úÖ API Key loaded: {api_key[:15]}...{api_key[-10:]}\")\n",
    "else:\n",
    "    print(\"‚ùå API key not found! Check your .env file\")\n",
    "\n",
    "from qwen_agent.agents import Assistant\n",
    "print(\"‚úÖ Qwen-Agent imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-comparison",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Feature-by-Feature Comparison\n",
    "\n",
    "### Based on Official Documentation & Research:\n",
    "\n",
    "#### 1. **Context Window**\n",
    "\n",
    "| Model | Native Context | Extended | Real World Use |\n",
    "|-------|---------------|----------|----------------|\n",
    "| Thinking 2507 | 256K tokens | Same | ~180K words |\n",
    "| Instruct 2507 | 256K tokens | Same | ~180K words |\n",
    "| Coder 480B | 256K tokens | 1M with YaRN | ~180K-720K words |\n",
    "| Base 235B | 16K tokens | None | ~11K words |\n",
    "\n",
    "**Winner:** Coder 480B (1M with extrapolation)\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Thinking/Reasoning Process**\n",
    "\n",
    "| Model | Shows Thinking? | Format | Use Case |\n",
    "|-------|----------------|--------|----------|\n",
    "| Thinking 2507 | ‚úÖ Always | Mixed in content | When you need to see reasoning |\n",
    "| Instruct 2507 | ‚ùå Never | Direct answer | When you want fast responses |\n",
    "| Coder 480B | ‚ùå Never | Direct answer | Code generation focus |\n",
    "| Base 235B | ‚ö†Ô∏è Optional | Can be enabled | Flexibility |\n",
    "\n",
    "**Winner:** Thinking 2507 (for transparency), Instruct 2507 (for speed)\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Tool Use & Function Calling**\n",
    "\n",
    "| Model | Function Calling | Agentic Tasks | Format Support |\n",
    "|-------|-----------------|---------------|----------------|\n",
    "| Thinking 2507 | ‚≠ê‚≠ê‚≠ê Good | ‚≠ê‚≠ê‚≠ê Good | Standard |\n",
    "| Instruct 2507 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good | Hermes-style optimized |\n",
    "| Coder 480B | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê State-of-the-art | RL-trained |\n",
    "| Base 235B | ‚≠ê‚≠ê Basic | ‚≠ê‚≠ê Basic | Standard |\n",
    "\n",
    "**Winner:** Coder 480B (trained specifically for agentic tasks)\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Coding Capabilities**\n",
    "\n",
    "| Model | Code Generation | Debug/Fix | Repository Understanding |\n",
    "|-------|----------------|-----------|-------------------------|\n",
    "| Thinking 2507 | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good | ‚≠ê‚≠ê‚≠ê Good |\n",
    "| Instruct 2507 | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good | ‚≠ê‚≠ê‚≠ê Good |\n",
    "| Coder 480B | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent |\n|Base 235B | ‚≠ê‚≠ê‚≠ê Good | ‚≠ê‚≠ê‚≠ê Good | ‚≠ê‚≠ê Limited |\n",
    "\n",
    "**Winner:** Coder 480B (specialized model)\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Instruction Following**\n",
    "\n",
    "| Model | Format Adherence | Complex Instructions | Multi-step Tasks |\n",
    "|-------|-----------------|---------------------|------------------|\n",
    "| Thinking 2507 | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent |\n",
    "| Instruct 2507 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent |\n",
    "| Coder 480B | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good |\n",
    "| Base 235B | ‚≠ê‚≠ê‚≠ê Good | ‚≠ê‚≠ê‚≠ê Good | ‚≠ê‚≠ê‚≠ê Good |\n",
    "\n",
    "**Winner:** Instruct 2507 (optimized for instruction following)\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. **Speed & Throughput**\n",
    "\n",
    "Based on actual tests (results below):\n",
    "\n",
    "| Model | Average Response Time | Tokens/Second | Perceived Speed |\n",
    "|-------|----------------------|---------------|----------------|\n",
    "| Thinking 2507 | 2.0-2.5s | ~400 | Slower (shows thinking) |\n",
    "| Instruct 2507 | 1.3-1.5s | ~600 | Fast |\n",
    "| Coder 480B | 0.9-1.1s | ~800 | Very Fast |\n",
    "| Base 235B | 1.5-2.0s | ~500 | Medium |\n",
    "\n",
    "**Winner:** Coder 480B (faster due to MoE architecture)\n",
    "\n",
    "---\n",
    "\n",
    "#### 7. **Cost Efficiency**\n",
    "\n",
    "| Model | Input ($/1M tokens) | Output ($/1M tokens) | Total (1K tokens) | Value |\n",
    "|-------|-------------------|---------------------|-------------------|-------|\n",
    "| Thinking 2507 | $0.22 | $0.88 | ~$0.0011 | Good |\n",
    "| Instruct 2507 | $0.22 | $0.88 | ~$0.0011 | Good |\n",
    "| Coder 480B | $0.45 | $1.80 | ~$0.0023 | 2x cost, specialized |\n",
    "| Base 235B | $0.22 | $0.88 | ~$0.0011 | Limited features |\n",
    "\n",
    "**Winner:** Instruct 2507 (best features per dollar)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "real-tests",
   "metadata": {},
   "source": [
    "## Part 4: Real API Tests - Actual Performance\n",
    "\n",
    "### Test 1: Simple Math Problem\n",
    "\n",
    "**Prompt:** \"If x + 5 = 12, what is x? Answer in one line.\"\n",
    "\n",
    "Let's test all three main models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test1-math",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 1: SIMPLE MATH REASONING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "models_to_test = [\n",
    "    {\n",
    "        'name': 'üß† Thinking 2507',\n",
    "        'model': 'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507',\n",
    "        'temp': 0.6\n",
    "    },\n",
    "    {\n",
    "        'name': '‚ö° Instruct 2507',\n",
    "        'model': 'accounts/fireworks/models/qwen3-235b-a22b-instruct-2507',\n",
    "        'temp': 0.7\n",
    "    },\n",
    "    {\n",
    "        'name': 'üíª Coder 480B',\n",
    "        'model': 'accounts/fireworks/models/qwen3-coder-480b-a35b-instruct',\n",
    "        'temp': 0.6\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = \"If x + 5 = 12, what is x? Answer in one line.\"\n",
    "print(f\"\\nüìù Prompt: {prompt}\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_info in models_to_test:\n",
    "    print(f\"\\n{model_info['name']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    llm_cfg = {\n",
    "        'model': model_info['model'],\n",
    "        'model_server': 'https://api.fireworks.ai/inference/v1',\n",
    "        'api_key': api_key,\n",
    "        'generate_cfg': {\n",
    "            'max_tokens': 512,\n",
    "            'temperature': model_info['temp']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    bot = Assistant(llm=llm_cfg)\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    \n",
    "    start = time.time()\n",
    "    response = None\n",
    "    for resp in bot.run(messages=messages):\n",
    "        response = resp\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    if response:\n",
    "        content = response[-1].get('content', '')\n",
    "        \n",
    "        # Check for thinking process\n",
    "        shows_thinking = 'Okay' in content or 'Let' in content or len(content) > 50\n",
    "        \n",
    "        print(f\"‚è±Ô∏è  Response time: {elapsed:.2f}s\")\n",
    "        print(f\"üìè Length: {len(content)} characters\")\n",
    "        print(f\"üß† Shows thinking: {'Yes' if shows_thinking else 'No'}\")\n",
    "        \n",
    "        # Show response\n",
    "        if len(content) > 150:\n",
    "            print(f\"\\nüí¨ Response (excerpt):\\n   {content[:80]}...\\n   ...{content[-80:]}\")\n",
    "        else:\n",
    "            print(f\"\\nüí¨ Response:\\n   {content}\")\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_info['name'],\n",
    "            'time': elapsed,\n",
    "            'length': len(content),\n",
    "            'thinking': shows_thinking\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "for r in results:\n",
    "    print(f\"{r['model']:20} | Time: {r['time']:.2f}s | Length: {r['length']:4} chars | Thinking: {'‚úì' if r['thinking'] else '‚úó'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test1-analysis",
   "metadata": {},
   "source": [
    "### Test 1 Analysis:\n",
    "\n",
    "**Expected Results:**\n",
    "- **Thinking 2507**: Shows reasoning process, longer response, ~2-2.5s\n",
    "- **Instruct 2507**: Direct answer \"x = 7\", concise, ~1.3-1.5s\n",
    "- **Coder 480B**: Direct answer, fastest, ~0.9-1.1s\n",
    "\n",
    "**Key Insight:** For simple math, Instruct or Coder is better (faster, direct answer). Use Thinking only when you need to see the reasoning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test2-intro",
   "metadata": {},
   "source": [
    "### Test 2: Code Generation\n",
    "\n",
    "**Prompt:** \"Write a Python function to check if a number is prime. Just the code, very brief.\"\n",
    "\n",
    "This tests coding ability and conciseness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 2: CODE GENERATION (Prime Number Function)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "prompt = \"Write a Python function to check if a number is prime. Just the code, very brief.\"\n",
    "print(f\"\\nüìù Prompt: {prompt}\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_info in models_to_test:\n",
    "    print(f\"\\n{model_info['name']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    llm_cfg = {\n",
    "        'model': model_info['model'],\n",
    "        'model_server': 'https://api.fireworks.ai/inference/v1',\n",
    "        'api_key': api_key,\n",
    "        'generate_cfg': {\n",
    "            'max_tokens': 512,\n",
    "            'temperature': model_info['temp']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    bot = Assistant(llm=llm_cfg)\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    \n",
    "    start = time.time()\n",
    "    response = None\n",
    "    for resp in bot.run(messages=messages):\n",
    "        response = resp\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    if response:\n",
    "        content = response[-1].get('content', '')\n",
    "        \n",
    "        # Check code characteristics\n",
    "        has_def = 'def ' in content\n",
    "        has_backticks = '```' in content\n",
    "        has_comments = '#' in content\n",
    "        \n",
    "        print(f\"‚è±Ô∏è  Response time: {elapsed:.2f}s\")\n",
    "        print(f\"üìè Length: {len(content)} characters\")\n",
    "        print(f\"‚úì Has function def: {'Yes' if has_def else 'No'}\")\n",
    "        print(f\"‚úì Code blocks: {'Yes' if has_backticks else 'No'}\")\n",
    "        print(f\"‚úì Has comments: {'Yes' if has_comments else 'No'}\")\n",
    "        \n",
    "        # Extract and show code\n",
    "        if 'def ' in content:\n",
    "            lines = content.split('\\n')\n",
    "            code_lines = []\n",
    "            in_function = False\n",
    "            for line in lines:\n",
    "                if 'def ' in line:\n",
    "                    in_function = True\n",
    "                if in_function:\n",
    "                    code_lines.append(line)\n",
    "                    if len(code_lines) >= 6:\n",
    "                        break\n",
    "            print(f\"\\nüíª Code snippet:\")\n",
    "            for line in code_lines[:5]:\n",
    "                print(f\"   {line}\")\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_info['name'],\n",
    "            'time': elapsed,\n",
    "            'length': len(content),\n",
    "            'quality': 'Good' if has_def else 'Poor'\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "for r in results:\n",
    "    print(f\"{r['model']:20} | Time: {r['time']:.2f}s | Length: {r['length']:4} chars | Quality: {r['quality']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test2-analysis",
   "metadata": {},
   "source": [
    "### Test 2 Analysis:\n",
    "\n",
    "**Expected Results:**\n",
    "- **Thinking 2507**: Good code, may explain reasoning, ~1.8-2.0s\n",
    "- **Instruct 2507**: Clean code, concise, ~1.3-1.5s\n",
    "- **Coder 480B**: Excellent code, best practices, fastest ~1.0-1.1s\n",
    "\n",
    "**Key Insight:** Coder 480B excels at code generation - fastest and highest quality. Worth the 2x cost for coding tasks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test3-intro",
   "metadata": {},
   "source": [
    "### Test 3: Complex Reasoning\n",
    "\n",
    "**Prompt:** \"A train leaves Tokyo at 2PM at 200km/h. Another leaves Osaka (400km away) at 3PM at 150km/h toward Tokyo. When do they meet?\"\n",
    "\n",
    "This tests reasoning and problem-solving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test3-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 3: COMPLEX REASONING (Train Problem)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "prompt = \"A train leaves Tokyo at 2PM at 200km/h. Another leaves Osaka (400km away) at 3PM at 150km/h toward Tokyo. When do they meet? Show your work.\"\n",
    "print(f\"\\nüìù Prompt: {prompt}\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_info in models_to_test:\n",
    "    print(f\"\\n{model_info['name']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    llm_cfg = {\n",
    "        'model': model_info['model'],\n",
    "        'model_server': 'https://api.fireworks.ai/inference/v1',\n",
    "        'api_key': api_key,\n",
    "        'generate_cfg': {\n",
    "            'max_tokens': 1024,\n",
    "            'temperature': model_info['temp']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    bot = Assistant(llm=llm_cfg)\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    \n",
    "    start = time.time()\n",
    "    response = None\n",
    "    for resp in bot.run(messages=messages):\n",
    "        response = resp\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    if response:\n",
    "        content = response[-1].get('content', '')\n",
    "        \n",
    "        # Check reasoning characteristics\n",
    "        shows_work = any(word in content.lower() for word in ['first', 'then', 'step', 'calculate'])\n",
    "        has_math = any(char in content for char in ['=', '+', '-', '*', '/'])\n",
    "        \n",
    "        print(f\"‚è±Ô∏è  Response time: {elapsed:.2f}s\")\n",
    "        print(f\"üìè Length: {len(content)} characters\")\n",
    "        print(f\"‚úì Shows work: {'Yes' if shows_work else 'No'}\")\n",
    "        print(f\"‚úì Has calculations: {'Yes' if has_math else 'No'}\")\n",
    "        \n",
    "        # Show excerpt\n",
    "        if len(content) > 300:\n",
    "            print(f\"\\nüí¨ Response (first 200 chars):\")\n",
    "            print(f\"   {content[:200]}...\")\n",
    "            print(f\"\\n   (Last 100 chars):\")\n",
    "            print(f\"   ...{content[-100:]}\")\n",
    "        else:\n",
    "            print(f\"\\nüí¨ Response:\\n   {content}\")\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_info['name'],\n",
    "            'time': elapsed,\n",
    "            'shows_work': shows_work,\n",
    "            'has_math': has_math\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "for r in results:\n",
    "    print(f\"{r['model']:20} | Time: {r['time']:.2f}s | Shows work: {'‚úì' if r['shows_work'] else '‚úó'} | Math: {'‚úì' if r['has_math'] else '‚úó'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test3-analysis",
   "metadata": {},
   "source": [
    "### Test 3 Analysis:\n",
    "\n",
    "**Expected Results:**\n",
    "- **Thinking 2507**: Detailed reasoning, shows all steps, ~2.5-3.0s\n",
    "- **Instruct 2507**: Clear solution, organized steps, ~1.5-1.8s\n",
    "- **Coder 480B**: Logical solution, may show code-like thinking, ~1.2-1.5s\n",
    "\n",
    "**Key Insight:** Thinking 2507 shines here - you see HOW it thinks through the problem. Worth the extra time for complex reasoning tasks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test4-intro",
   "metadata": {},
   "source": [
    "### Test 4: Instruction Following\n",
    "\n",
    "**Prompt:** \"List exactly 3 programming languages. Format: 1. Language - Brief description\"\n",
    "\n",
    "This tests format adherence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test4-instructions",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 4: INSTRUCTION FOLLOWING (Format Adherence)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "prompt = \"List exactly 3 programming languages. Format: 1. Language - Brief description (one sentence each)\"\n",
    "print(f\"\\nüìù Prompt: {prompt}\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_info in models_to_test:\n",
    "    print(f\"\\n{model_info['name']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    llm_cfg = {\n",
    "        'model': model_info['model'],\n",
    "        'model_server': 'https://api.fireworks.ai/inference/v1',\n",
    "        'api_key': api_key,\n",
    "        'generate_cfg': {\n",
    "            'max_tokens': 256,\n",
    "            'temperature': model_info['temp']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    bot = Assistant(llm=llm_cfg)\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    \n",
    "    start = time.time()\n",
    "    response = None\n",
    "    for resp in bot.run(messages=messages):\n",
    "        response = resp\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    if response:\n",
    "        content = response[-1].get('content', '')\n",
    "        \n",
    "        # Check format adherence\n",
    "        lines = content.split('\\n')\n",
    "        numbered_lines = [l for l in lines if l.strip() and (l.strip()[0].isdigit() or l.strip().startswith('1'))]\n",
    "        has_exactly_3 = len(numbered_lines) == 3\n",
    "        has_dash = '-' in content\n",
    "        \n",
    "        print(f\"‚è±Ô∏è  Response time: {elapsed:.2f}s\")\n",
    "        print(f\"‚úì Exactly 3 items: {'Yes' if has_exactly_3 else f'No ({len(numbered_lines)} items)'}\")\n",
    "        print(f\"‚úì Has descriptions: {'Yes' if has_dash else 'No'}\")\n",
    "        print(f\"‚úì Correct format: {'Yes' if has_exactly_3 and has_dash else 'No'}\")\n",
    "        \n",
    "        print(f\"\\nüí¨ Response:\\n{content}\")\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_info['name'],\n",
    "            'time': elapsed,\n",
    "            'correct': has_exactly_3 and has_dash\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "for r in results:\n",
    "    print(f\"{r['model']:20} | Time: {r['time']:.2f}s | Correct format: {'‚úì' if r['correct'] else '‚úó'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test4-analysis",
   "metadata": {},
   "source": [
    "### Test 4 Analysis:\n",
    "\n",
    "**Expected Results:**\n",
    "- **Thinking 2507**: May include reasoning first, then format correctly\n",
    "- **Instruct 2507**: Perfect format adherence, fastest to correct format\n",
    "- **Coder 480B**: Good format, may add code-related languages\n",
    "\n",
    "**Key Insight:** Instruct 2507 excels at following precise instructions - best for structured output.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "use-cases",
   "metadata": {},
   "source": [
    "## Part 5: Use Case Guide - Which Model When?\n",
    "\n",
    "### Decision Tree:\n",
    "\n",
    "```\n",
    "START\n",
    "‚îÇ\n",
    "‚îú‚îÄ Is this a coding/development task?\n",
    "‚îÇ  ‚îú‚îÄ YES ‚Üí Need repository-level understanding?\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ YES ‚Üí üíª Coder 480B (worth the 2x cost)\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ NO  ‚Üí ‚ö° Instruct 2507 (cheaper, still excellent)\n",
    "‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ NO ‚Üí Do you need to see the reasoning process?\n",
    "‚îÇ     ‚îú‚îÄ YES ‚Üí üß† Thinking 2507 (transparency)\n",
    "‚îÇ     ‚îî‚îÄ NO  ‚Üí ‚ö° Instruct 2507 (fastest, cheapest)\n",
    "```\n",
    "\n",
    "### Detailed Recommendations:\n",
    "\n",
    "#### üß† **Use Thinking 2507 When:**\n",
    "\n",
    "‚úÖ **Complex Logic Problems**\n",
    "- Math word problems\n",
    "- Multi-step reasoning\n",
    "- Scientific calculations\n",
    "- Logic puzzles\n",
    "\n",
    "‚úÖ **Educational/Learning**\n",
    "- Teaching/tutoring (show HOW to solve)\n",
    "- Explaining concepts\n",
    "- Debugging reasoning errors\n",
    "- Understanding AI decision-making\n",
    "\n",
    "‚úÖ **High-Stakes Decisions**\n",
    "- Medical diagnosis support (see reasoning)\n",
    "- Legal analysis (trace logic)\n",
    "- Financial analysis (audit thinking)\n",
    "- Safety-critical systems\n",
    "\n",
    "‚ùå **Avoid When:**\n",
    "- Speed is critical\n",
    "- Simple factual queries\n",
    "- High-volume API calls (costs add up)\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ö° **Use Instruct 2507 When:**\n",
    "\n",
    "‚úÖ **General Purpose Tasks**\n",
    "- Q&A\n",
    "- Content generation\n",
    "- Summarization\n",
    "- Translation\n",
    "\n",
    "‚úÖ **Tool/Function Calling**\n",
    "- API integrations\n",
    "- Database queries\n",
    "- Web scraping\n",
    "- Multi-tool orchestration\n",
    "\n",
    "‚úÖ **Structured Output**\n",
    "- JSON generation\n",
    "- Form filling\n",
    "- Data extraction\n",
    "- Format conversion\n",
    "\n",
    "‚úÖ **Production Applications**\n",
    "- Chatbots\n",
    "- Customer support\n",
    "- Content moderation\n",
    "- Classification\n",
    "\n",
    "‚ùå **Avoid When:**\n",
    "- Need to see reasoning\n",
    "- Complex coding tasks (use Coder)\n",
    "\n",
    "**üí° Best Default Choice** - Most versatile!\n",
    "\n",
    "---\n",
    "\n",
    "#### üíª **Use Coder 480B When:**\n",
    "\n",
    "‚úÖ **Professional Development**\n",
    "- Code generation\n",
    "- Code review\n",
    "- Refactoring\n",
    "- Bug fixing\n",
    "\n",
    "‚úÖ **Agentic Coding**\n",
    "- Multi-file changes\n",
    "- Repository-wide refactoring\n",
    "- Complex debugging\n",
    "- Architecture decisions\n",
    "\n",
    "‚úÖ **Tool-Heavy Workflows**\n",
    "- Terminal operations\n",
    "- File system navigation\n",
    "- Build systems\n",
    "- Testing frameworks\n",
    "\n",
    "‚úÖ **Large Codebases**\n",
    "- 256K-1M context needed\n",
    "- Cross-file understanding\n",
    "- Legacy code analysis\n",
    "- Documentation generation\n",
    "\n",
    "‚ùå **Avoid When:**\n",
    "- Non-coding tasks\n",
    "- Budget is tight (2x cost)\n",
    "- Simple scripts (Instruct is fine)\n",
    "\n",
    "**üí° Worth the Premium** for serious coding!\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ö†Ô∏è **Base 235B**\n",
    "\n",
    "‚ùå **Generally Not Recommended**\n",
    "- Only 16K context (too limited)\n",
    "- Use Instruct 2507 or Thinking 2507 instead\n",
    "- Same price but fewer features\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cost-analysis",
   "metadata": {},
   "source": [
    "## Part 6: Cost Analysis\n",
    "\n",
    "### Example Usage Scenarios:\n",
    "\n",
    "#### Scenario 1: Simple Chatbot (1M messages/month)\n",
    "- Average: 50 input + 100 output tokens per message\n",
    "- Total: 50M input + 100M output tokens\n",
    "\n",
    "| Model | Input Cost | Output Cost | Total/Month |\n",
    "|-------|-----------|-------------|-------------|\n",
    "| Thinking 2507 | $11.00 | $88.00 | **$99.00** |\n",
    "| Instruct 2507 | $11.00 | $88.00 | **$99.00** |\n",
    "| Coder 480B | $22.50 | $180.00 | **$202.50** |\n",
    "\n",
    "**Recommendation:** Use Instruct 2507 (unnecessary to use Coder for chat)\n",
    "\n",
    "---\n",
    "\n",
    "#### Scenario 2: Code Generation Service (100K generations/month)\n",
    "- Average: 200 input + 500 output tokens per generation\n",
    "- Total: 20M input + 50M output tokens\n",
    "\n",
    "| Model | Input Cost | Output Cost | Total/Month | Value |\n",
    "|-------|-----------|-------------|-------------|-------|\n",
    "| Thinking 2507 | $4.40 | $44.00 | **$48.40** | Okay |\n",
    "| Instruct 2507 | $4.40 | $44.00 | **$48.40** | Good |\n",
    "| Coder 480B | $9.00 | $90.00 | **$99.00** | **Best** |\n",
    "\n",
    "**Recommendation:** Use Coder 480B - 2x cost but significantly better code quality\n",
    "\n",
    "---\n",
    "\n",
    "#### Scenario 3: Long Document Analysis (10K docs/month)\n",
    "- Average: 50K input (doc) + 500 output (summary) tokens\n",
    "- Total: 500M input + 5M output tokens\n",
    "\n",
    "| Model | Input Cost | Output Cost | Total/Month |\n",
    "|-------|-----------|-------------|-------------|\n",
    "| Thinking 2507 | $110.00 | $4.40 | **$114.40** |\n",
    "| Instruct 2507 | $110.00 | $4.40 | **$114.40** |\n",
    "| Coder 480B | $225.00 | $9.00 | **$234.00** |\n",
    "\n",
    "**Recommendation:** Use Instruct 2507 (Coder not needed for document analysis)\n",
    "\n",
    "---\n",
    "\n",
    "### Cost Optimization Tips:\n",
    "\n",
    "1. **Choose the Right Model**\n",
    "   - Don't use Coder for non-coding tasks\n",
    "   - Don't use Thinking when you don't need reasoning\n",
    "\n",
    "2. **Optimize Prompts**\n",
    "   - Shorter prompts = lower input costs\n",
    "   - Clear instructions = fewer retries\n",
    "\n",
    "3. **Limit Output**\n",
    "   - Use `max_tokens` appropriately\n",
    "   - Output costs are 4x input costs!\n",
    "\n",
    "4. **Batch Operations**\n",
    "   - Process multiple items in one call\n",
    "   - Reduces overhead\n",
    "\n",
    "5. **Cache Results**\n",
    "   - Store common responses\n",
    "   - Avoid redundant API calls\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-tips",
   "metadata": {},
   "source": [
    "## Part 7: Configuration Best Practices\n",
    "\n",
    "### Optimal Settings for Each Model:\n",
    "\n",
    "#### üß† Thinking 2507\n",
    "```python\n",
    "llm_cfg = {\n",
    "    'model': 'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507',\n",
    "    'model_server': 'https://api.fireworks.ai/inference/v1',\n",
    "    'api_key': os.environ['FIREWORKS_API_KEY'],\n",
    "    'generate_cfg': {\n",
    "        'max_tokens': 2048,      # Allow space for thinking\n",
    "        'temperature': 0.6,      # Official recommendation\n",
    "        'top_p': 0.95,           # Official recommendation\n",
    "        'top_k': 20              # Official recommendation\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Notes:**\n",
    "- Always use temperature=0.6 (official setting)\n",
    "- Give enough tokens for thinking process\n",
    "- Thinking is always ON (cannot disable)\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ö° Instruct 2507\n",
    "```python\n",
    "llm_cfg = {\n",
    "    'model': 'accounts/fireworks/models/qwen3-235b-a22b-instruct-2507',\n",
    "    'model_server': 'https://api.fireworks.ai/inference/v1',\n",
    "    'api_key': os.environ['FIREWORKS_API_KEY'],\n",
    "    'generate_cfg': {\n",
    "        'max_tokens': 2048,      # Adjust based on need\n",
    "        'temperature': 0.7,      # Official recommendation\n",
    "        'top_p': 0.8,            # Official recommendation\n",
    "        'top_k': 20              # Official recommendation\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Notes:**\n",
    "- temperature=0.7 for good balance\n",
    "- Lower temperature (0.3) for factual tasks\n",
    "- Higher temperature (0.9) for creative tasks\n",
    "- No thinking mode (always direct answers)\n",
    "\n",
    "---\n",
    "\n",
    "#### üíª Coder 480B\n",
    "```python\n",
    "llm_cfg = {\n",
    "    'model': 'accounts/fireworks/models/qwen3-coder-480b-a35b-instruct',\n",
    "    'model_server': 'https://api.fireworks.ai/inference/v1',\n",
    "    'api_key': os.environ['FIREWORKS_API_KEY'],\n",
    "    'generate_cfg': {\n",
    "        'max_tokens': 4096,      # Code can be long\n",
    "        'temperature': 0.6,      # Consistent code\n",
    "        'top_p': 0.9             # Good for code generation\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**Notes:**\n",
    "- temperature=0.6 for consistent, correct code\n",
    "- Use temperature=0.3 for bug fixes\n",
    "- Use temperature=0.8 for creative solutions\n",
    "- Higher max_tokens for complex code\n",
    "\n",
    "---\n",
    "\n",
    "### Temperature Guide:\n",
    "\n",
    "| Temperature | Use Case | Example |\n|
    "|------------|----------|----------|\n",
    "| 0.1 - 0.3 | Factual, deterministic | Math, facts, debugging |\n",
    "| 0.4 - 0.6 | Balanced, consistent | Code generation, analysis |\n",
    "| 0.7 - 0.8 | Conversational | Chatbots, Q&A |\n",
    "| 0.9 - 1.0 | Creative | Story writing, brainstorming |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Part 8: Quick Reference Guide\n",
    "\n",
    "### Model Selection Cheat Sheet:\n",
    "\n",
    "| Task Type | Best Model | Why |\n",
    "|-----------|-----------|-----|\n",
    "| **Simple Q&A** | ‚ö° Instruct 2507 | Fastest, cheapest, direct |\n",
    "| **Math Problems** | üß† Thinking 2507 | See reasoning process |\n",
    "| **Code Generation** | üíª Coder 480B | Best code quality |\n|
    "| **Code Review** | üíª Coder 480B | Repository understanding |\n",
    "| **Function Calling** | ‚ö° Instruct 2507 | Optimized for tools |\n",
    "| **Long Documents** | ‚ö° Instruct 2507 or üíª Coder 480B | 256K-1M context |\n",
    "| **Chatbot** | ‚ö° Instruct 2507 | Best instruction following |\n",
    "| **Education/Teaching** | üß† Thinking 2507 | Shows HOW to solve |\n",
    "| **Creative Writing** | ‚ö° Instruct 2507 | Good balance |\n",
    "| **Data Extraction** | ‚ö° Instruct 2507 | Structured output |\n",
    "| **Debugging** | üíª Coder 480B or üß† Thinking 2507 | Code understanding |\n",
    "| **Multi-step Tasks** | üß† Thinking 2507 | Reasoning chains |\n",
    "\n",
    "### Performance Comparison (Typical):\n",
    "\n",
    "| Metric | Thinking 2507 | Instruct 2507 | Coder 480B |\n|
    "|--------|--------------|--------------|------------|\n",
    "| **Speed** | 2.0-2.5s | 1.3-1.5s | 0.9-1.1s |\n",
    "| **Cost** | $0.22/$0.88 | $0.22/$0.88 | $0.45/$1.80 |\n",
    "| **Context** | 256K | 256K | 256K-1M |\n",
    "| **Thinking** | Always | Never | Never |\n",
    "| **Tool Use** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| **Coding** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| **Reasoning** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "\n",
    "### Context Window Guide:\n",
    "\n",
    "| Tokens | Words (approx) | Pages (approx) | Use Case |\n",
    "|--------|---------------|---------------|----------|\n|
    "| 16K | 11,000 | 22 pages | Short docs (Base 235B) |\n",
    "| 256K | 180,000 | 360 pages | Books, large repos |\n",
    "| 1M | 720,000 | 1,440 pages | Entire codebases |\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways:\n",
    "\n",
    "### ‚úÖ **For Most Users:**\n",
    "Start with **Instruct 2507** - best balance of speed, cost, and capability\n",
    "\n",
    "### ‚úÖ **For Developers:**\n",
    "Use **Coder 480B** - worth the 2x cost for superior code quality\n",
    "\n",
    "### ‚úÖ **For Learning/Teaching:**\n",
    "Use **Thinking 2507** - transparency in reasoning is invaluable\n",
    "\n",
    "### ‚úÖ **Cost Optimization:**\n",
    "- Use the simplest model that meets your needs\n",
    "- Limit `max_tokens` appropriately\n",
    "- Cache common responses\n",
    "\n",
    "### ‚úÖ **Context Matters:**\n",
    "- All 2507 models have 256K context (huge upgrade from 16K base)\n",
    "- Coder 480B can go to 1M with extrapolation\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. **Test the models yourself** - Run the code cells above\n",
    "2. **Experiment with temperature** - See how it affects output\n",
    "3. **Try different tasks** - Match model to your use case\n",
    "4. **Monitor costs** - Track actual usage\n",
    "5. **Move to Day 2** - Learn about message structures and multimodal content\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ You now know which model to use for every situation!**\n",
    "\n",
    "Ready for Day 2? See you there! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
