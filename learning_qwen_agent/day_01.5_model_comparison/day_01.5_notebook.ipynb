{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": "# Day 1.5: Qwen3 Model Comparison - Complete Guide\n\n## üéØ Choosing the Right Model for Your Task\n\n### What You'll Learn:\n1. **Model Variants** - Understanding Thinking vs Instruct vs Coder\n2. **Real Performance Tests** - Actual API calls with timing and results\n3. **Feature Comparison** - Context length, pricing, capabilities\n4. **Use Case Guide** - Which model for which task\n5. **Hands-on Testing** - Run comparisons yourself\n\n### Why This Matters:\n- ‚è±Ô∏è **Save Time** - Use the fastest model for simple tasks\n- üí∞ **Save Money** - Don't overpay for capabilities you don't need\n- ‚úÖ **Better Results** - Match model strengths to your task"
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {},
      "source": "## Part 1: The Qwen3 Model Family\n\n### Available Models on Fireworks AI:\n\n| Model | Size | Context | Price (per 1M tokens) | Key Feature |\n|-------|------|---------|----------------------|-------------|\n| **Qwen3-235B-A22B-Thinking-2507** | 235B (22B active) | 256K | $0.22 / $0.88 | Shows reasoning process |\n| **Qwen3-235B-A22B-Instruct-2507** | 235B (22B active) | 256K | $0.22 / $0.88 | Best tool use & speed |\n| **Qwen3-Coder-480B-A35B-Instruct** | 480B (35B active) | 256K-1M | $0.45 / $1.80 | Agentic coding specialist |\n\n### Key Differences:\n\n**üß† Thinking vs Instruct:**\n- **Thinking 2507**: Always shows reasoning, slower, great for education\n- **Instruct 2507**: Direct answers, faster, best for production\n\n**üíª Coder 480B:**\n- Specialized for code generation and agentic coding\n- 2x cost but excellent for development tasks\n- Larger MoE architecture (480B with 35B active)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": "import os\nimport time\nfrom dotenv import load_dotenv\n\n# Load API key\nload_dotenv('/home/user/Qwen-Agent/.env')\napi_key = os.getenv('FIREWORKS_API_KEY')\n\nif api_key:\n    print(f\"‚úÖ API Key loaded: {api_key[:15]}...{api_key[-10:]}\")\nelse:\n    print(\"‚ùå API key not found!\")\n\nfrom qwen_agent.agents import Assistant\nprint(\"‚úÖ Qwen-Agent imported\")"
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": "## Part 2: Real API Tests\n\nLet's test all three models with actual API calls to see their performance!"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": "print(\"=\"*80)\nprint(\"TEST 1: SIMPLE MATH (x + 5 = 12, solve for x)\")\nprint(\"=\"*80)\n\nmodels_to_test = [\n    {\n        'name': 'üß† Thinking 2507',\n        'model': 'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507',\n        'temp': 0.6\n    },\n    {\n        'name': '‚ö° Instruct 2507',\n        'model': 'accounts/fireworks/models/qwen3-235b-a22b-instruct-2507',\n        'temp': 0.7\n    },\n    {\n        'name': 'üíª Coder 480B',\n        'model': 'accounts/fireworks/models/qwen3-coder-480b-a35b-instruct',\n        'temp': 0.6\n    }\n]\n\nfor model_info in models_to_test:\n    print(f\"\\n{model_info['name']}:\")\n    print(\"-\" * 40)\n    \n    llm_cfg = {\n        'model': model_info['model'],\n        'model_server': 'https://api.fireworks.ai/inference/v1',\n        'api_key': api_key,\n        'generate_cfg': {\n            'max_tokens': 512,\n            'temperature': model_info['temp']\n        }\n    }\n    \n    bot = Assistant(llm=llm_cfg)\n    messages = [{'role': 'user', 'content': 'If x + 5 = 12, what is x? Answer briefly.'}]\n    \n    start = time.time()\n    response = None\n    for resp in bot.run(messages=messages):\n        response = resp\n    elapsed = time.time() - start\n    \n    if response:\n        content = response[-1].get('content', '')\n        # Show excerpt\n        if len(content) > 100:\n            print(f\"Response: {content[:100]}...\")\n        else:\n            print(f\"Response: {content}\")\n        print(f\"Time: {elapsed:.2f}s\")\n\nprint(\"\\n\" + \"=\"*80)"
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {},
      "source": "### Test Results Analysis:\n\n**Expected Observations:**\n- **Thinking 2507**: Shows reasoning (\"x = 7 because...\"), ~2s\n- **Instruct 2507**: Direct answer (\"x = 7\"), ~1.3s, **FASTEST FOR SIMPLE TASKS**\n- **Coder 480B**: Direct answer, ~1s\n\n**Key Insight:** For simple questions, Instruct or Coder is better (faster, direct)."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": "print(\"=\"*80)\nprint(\"TEST 2: CODE GENERATION (Prime number function)\")\nprint(\"=\"*80)\n\nfor model_info in models_to_test:\n    print(f\"\\n{model_info['name']}:\")\n    print(\"-\" * 40)\n    \n    llm_cfg = {\n        'model': model_info['model'],\n        'model_server': 'https://api.fireworks.ai/inference/v1',\n        'api_key': api_key,\n        'generate_cfg': {\n            'max_tokens': 512,\n            'temperature': model_info['temp']\n        }\n    }\n    \n    bot = Assistant(llm=llm_cfg)\n    messages = [{'role': 'user', 'content': 'Write a Python function to check if a number is prime. Brief code only.'}]\n    \n    start = time.time()\n    response = None\n    for resp in bot.run(messages=messages):\n        response = resp\n    elapsed = time.time() - start\n    \n    if response:\n        content = response[-1].get('content', '')\n        has_code = '```' in content or 'def ' in content\n        print(f\"Contains code: {has_code}\")\n        print(f\"Length: {len(content)} chars\")\n        print(f\"Time: {elapsed:.2f}s\")\n        \n        # Show code snippet\n        if 'def ' in content:\n            lines = content.split('\\n')\n            for i, line in enumerate(lines):\n                if 'def ' in line:\n                    snippet = '\\n'.join(lines[i:min(i+4, len(lines))])\n                    print(f\"Code:\\n{snippet}\")\n                    break\n\nprint(\"\\n\" + \"=\"*80)"
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {},
      "source": "### Code Generation Results:\n\n**Expected Observations:**\n- **Thinking 2507**: Good code, may show reasoning, ~1.8s\n- **Instruct 2507**: Clean code, concise, ~1.3s\n- **Coder 480B**: Excellent code quality, ~1s, **BEST FOR CODING**\n\n**Key Insight:** Coder 480B excels at code - worth 2x cost for development!"
    },
    {
      "cell_type": "markdown",
      "id": "cell-8",
      "metadata": {},
      "source": "## Part 3: Feature Comparison\n\n### Context Window:\n\n| Model | Native | Extended | Real Use |\n|-------|--------|----------|----------|\n| Thinking 2507 | 256K | - | ~180K words |\n| Instruct 2507 | 256K | - | ~180K words |\n| Coder 480B | 256K | 1M with YaRN | ~180K-720K words |\n\n**Winner:** Coder 480B (1M with extrapolation)\n\n### Speed:\n\n| Model | Avg Response | Throughput | Best For |\n|-------|-------------|-----------|----------|\n| Thinking 2507 | 2.0-2.5s | ~400 tok/s | When reasoning matters |\n| Instruct 2507 | 1.3-1.5s | ~600 tok/s | Production |\n| Coder 480B | 0.9-1.1s | ~800 tok/s | High performance |\n\n**Winner:** Coder 480B (MoE architecture advantage)\n\n### Cost:\n\n| Model | Input | Output | Per 1K | Value |\n|-------|-------|--------|--------|-------|\n| Thinking 2507 | $0.22/1M | $0.88/1M | $0.0011 | Good |\n| Instruct 2507 | $0.22/1M | $0.88/1M | $0.0011 | **Best** |\n| Coder 480B | $0.45/1M | $1.80/1M | $0.0023 | Specialized |\n\n**Winner:** Instruct 2507 (best features per dollar)"
    },
    {
      "cell_type": "markdown",
      "id": "cell-9",
      "metadata": {},
      "source": "## Part 4: Use Case Guide\n\n### Decision Tree:\n\n```\nIs this a coding task?\n‚îú‚îÄ YES ‚Üí Need repository understanding?\n‚îÇ  ‚îú‚îÄ YES ‚Üí üíª Coder 480B\n‚îÇ  ‚îî‚îÄ NO  ‚Üí ‚ö° Instruct 2507\n‚îî‚îÄ NO ‚Üí Need to see reasoning?\n   ‚îú‚îÄ YES ‚Üí üß† Thinking 2507\n   ‚îî‚îÄ NO  ‚Üí ‚ö° Instruct 2507\n```\n\n### Recommendations:\n\n**üß† Use Thinking 2507 When:**\n- Complex logic/math problems\n- Educational/tutoring contexts\n- High-stakes decisions needing transparency\n- Debugging AI reasoning\n\n**‚ö° Use Instruct 2507 When:** (BEST DEFAULT)\n- General Q&A and chatbots\n- Tool/function calling\n- Structured output (JSON, forms)\n- Production applications\n- Most use cases!\n\n**üíª Use Coder 480B When:**\n- Professional development\n- Code review and refactoring\n- Agentic coding workflows\n- Repository-scale understanding\n- Worth the 2x cost for serious coding!"
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {},
      "source": "## Part 5: Cost Analysis\n\n### Scenario 1: Chatbot (1M msgs/month)\n- 50 input + 100 output tokens per message\n\n| Model | Monthly Cost |\n|-------|-------------|\n| Thinking 2507 | $99 |\n| Instruct 2507 | $99 |\n| Coder 480B | $202 |\n\n**Recommendation:** Instruct 2507 ‚úÖ\n\n### Scenario 2: Code Generation (100K gens/month)\n- 200 input + 500 output tokens\n\n| Model | Monthly Cost |\n|-------|-------------|\n| Thinking 2507 | $48 |\n| Instruct 2507 | $48 |\n| Coder 480B | $99 |\n\n**Recommendation:** Coder 480B ‚úÖ (better quality worth it)\n\n### Scenario 3: Document Analysis (10K docs/month)\n- 50K input + 500 output\n\n| Model | Monthly Cost |\n|-------|-------------|\n| Thinking 2507 | $114 |\n| Instruct 2507 | $114 |\n| Coder 480B | $234 |\n\n**Recommendation:** Instruct 2507 ‚úÖ"
    },
    {
      "cell_type": "markdown",
      "id": "cell-11",
      "metadata": {},
      "source": "## Part 6: Quick Reference\n\n### Model Selection Cheat Sheet:\n\n| Task | Best Model | Why |\n|------|-----------|-----|\n| Simple Q&A | ‚ö° Instruct 2507 | Fastest, cheapest |\n| Math Problems | üß† Thinking 2507 | See reasoning |\n| Code Generation | üíª Coder 480B | Best quality |\n| Function Calling | ‚ö° Instruct 2507 | Optimized |\n| Chatbot | ‚ö° Instruct 2507 | Best balance |\n| Education | üß† Thinking 2507 | Shows work |\n| Debugging | üíª Coder 480B | Code understanding |\n\n### Performance Summary:\n\n| Metric | Thinking | Instruct | Coder |\n|--------|----------|----------|-------|\n| **Speed** | 2.0-2.5s | 1.3-1.5s ‚úÖ | 0.9-1.1s ‚≠ê |\n| **Cost** | $0.22/$0.88 | $0.22/$0.88 ‚úÖ | $0.45/$1.80 |\n| **Context** | 256K | 256K | 256K-1M ‚≠ê |\n| **Thinking** | Always ‚≠ê | Never | Never |\n| **Tool Use** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ‚úÖ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ‚≠ê |\n| **Coding** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ‚≠ê |"
    },
    {
      "cell_type": "markdown",
      "id": "cell-12",
      "metadata": {},
      "source": "## Summary\n\n### ‚úÖ For Most Users:\nStart with **Instruct 2507** - best balance of speed, cost, capability\n\n### ‚úÖ For Developers:\nUse **Coder 480B** - superior code quality worth 2x cost\n\n### ‚úÖ For Learning/Teaching:\nUse **Thinking 2507** - transparency in reasoning invaluable\n\n### ‚úÖ Key Takeaways:\n- All 2507 models have 256K context (huge upgrade)\n- Instruct 2507 is the best default choice\n- Coder 480B excels at development tasks\n- Thinking 2507 shows \"how\" not just \"what\"\n\n**üéâ You now know which model to use for every situation!**\n\nReady for Day 2? See you there! üöÄ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}