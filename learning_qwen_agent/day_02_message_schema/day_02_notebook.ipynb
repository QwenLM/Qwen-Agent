{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: Message Schema & Communication\n",
    "\n",
    "## Understanding How Agents Communicate\n",
    "\n",
    "### Today's Learning Objectives:\n",
    "1. Deep dive into the `Message` class structure\n",
    "2. Understand different role types and their purposes\n",
    "3. Work with `ContentItem` for multimodal messages\n",
    "4. Learn about `FunctionCall` messages (preview for Day 6)\n",
    "5. Build complex, multi-modal conversation histories\n",
    "6. Understand reasoning_content for advanced models\n",
    "\n",
    "### Prerequisites:\n",
    "- Completed Day 1\n",
    "- Qwen-Agent installed and configured\n",
    "- API key set up\n",
    "\n",
    "### Time Required: 1.5-2 hours\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Why Messages Matter\n",
    "\n",
    "### The Communication Protocol\n",
    "\n",
    "Everything in Qwen-Agent flows through **Messages**. They are:\n",
    "- The **input** to agents (what you say)\n",
    "- The **output** from agents (what they respond)\n",
    "- The **history** of conversations (context)\n",
    "- The **mechanism** for tool calls (function execution)\n",
    "\n",
    "### Message Flow Diagram:\n",
    "\n",
    "```\n",
    "User Creates Message\n",
    "        |\n",
    "        v\n",
    "[Message(role='user', content='...')]\n",
    "        |\n",
    "        v\n",
    "    Agent.run(messages)\n",
    "        |\n",
    "        v\n",
    "    LLM processes\n",
    "        |\n",
    "        v\n",
    "[Message(role='assistant', content='...'),\n",
    " Message(role='assistant', function_call=...)]\n",
    "        |\n",
    "        v\n",
    "    User receives response\n",
    "```\n",
    "\n",
    "### Key Insight:\n",
    "Messages are **NOT** just strings. They are structured data with:\n",
    "- **role**: Who is speaking\n",
    "- **content**: What is being said (can be text, image, etc.)\n",
    "- **metadata**: Additional information (name, function calls, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Message Class Structure\n",
    "\n",
    "### Source Code Location:\n",
    "`/qwen_agent/llm/schema.py` (lines 132-165)\n",
    "\n",
    "### Message Class Definition:\n",
    "\n",
    "```python\n",
    "class Message(BaseModelCompatibleDict):\n",
    "    role: str                                      # Required: 'user', 'assistant', 'system', 'function'\n",
    "    content: Union[str, List[ContentItem]]         # Required: Message content\n",
    "    reasoning_content: Optional[Union[str, List[ContentItem]]] = None  # For reasoning models\n",
    "    name: Optional[str] = None                     # Agent/tool name\n",
    "    function_call: Optional[FunctionCall] = None   # Tool invocation data\n",
    "    extra: Optional[dict] = None                   # Additional metadata\n",
    "```\n",
    "\n",
    "Let's explore each field in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: The `role` Field\n",
    "\n",
    "### Four Role Types (from schema.py lines 26-29):\n",
    "\n",
    "```python\n",
    "SYSTEM = 'system'      # Instructions for the agent\n",
    "USER = 'user'          # Input from human/user\n",
    "ASSISTANT = 'assistant'  # Response from agent/LLM\n",
    "FUNCTION = 'function'   # Tool execution results\n",
    "```\n",
    "\n",
    "### Role Descriptions:\n",
    "\n",
    "| Role | Purpose | Who Creates It | Example |\n",
    "|------|---------|----------------|----------|\n",
    "| `system` | Give instructions/context to agent | Developer | \"You are a helpful assistant\" |\n",
    "| `user` | User queries and inputs | User/Application | \"What's the weather?\" |\n",
    "| `assistant` | Agent responses | Agent/LLM | \"The weather is sunny\" |\n",
    "| `function` | Tool execution results | Agent (after running tool) | `{\"temperature\": 72}` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# FIREWORKS API CONFIGURATION\n",
    "# ================================================\n",
    "import os\n",
    "\n",
    "# Set API credentials\n",
    "os.environ['FIREWORKS_API_KEY'] = 'fw_3ZTLPrnEtuscTUPYy3sYx3ag'\n",
    "\n",
    "# Standard configuration for Fireworks Qwen3-235B-A22B-Thinking\n",
    "llm_cfg_fireworks = {\n",
    "    'model': 'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507',\n",
    "    'model_server': 'https://api.fireworks.ai/inference/v1',\n",
    "    'api_key': os.environ['FIREWORKS_API_KEY'],\n",
    "    'generate_cfg': {\n",
    "        'max_tokens': 32768,\n",
    "        'temperature': 0.6,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use this as default llm_cfg\n",
    "llm_cfg = llm_cfg_fireworks\n",
    "\n",
    "print('\u2705 Configured for Fireworks API')\n",
    "print(f'   Model: Qwen3-235B-A22B-Thinking-2507')\n",
    "print(f'   Max tokens: 32,768')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Message class\n",
    "from qwen_agent.llm.schema import Message, SYSTEM, USER, ASSISTANT, FUNCTION\n",
    "\n",
    "# Example 1: System message\n",
    "system_msg = Message(\n",
    "    role=SYSTEM,\n",
    "    content='You are a helpful AI assistant specialized in Python programming.'\n",
    ")\n",
    "\n",
    "# Example 2: User message\n",
    "user_msg = Message(\n",
    "    role=USER,\n",
    "    content='How do I read a file in Python?'\n",
    ")\n",
    "\n",
    "# Example 3: Assistant message\n",
    "assistant_msg = Message(\n",
    "    role=ASSISTANT,\n",
    "    content='You can use the `open()` function with a context manager...'\n",
    ")\n",
    "\n",
    "# Example 4: Function message (we'll learn more about this on Day 6)\n",
    "function_msg = Message(\n",
    "    role=FUNCTION,\n",
    "    content='{\"result\": \"File read successfully\"}',\n",
    "    name='read_file'  # Name of the tool that was executed\n",
    ")\n",
    "\n",
    "print(\"System Message:\")\n",
    "print(system_msg)\n",
    "print(\"\\nUser Message:\")\n",
    "print(user_msg)\n",
    "print(\"\\nAssistant Message:\")\n",
    "print(assistant_msg)\n",
    "print(\"\\nFunction Message:\")\n",
    "print(function_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message as Dict:\n",
    "\n",
    "The `Message` class extends `BaseModelCompatibleDict`, which means you can use it like a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a message\n",
    "msg = Message(role='user', content='Hello!')\n",
    "\n",
    "# Access like a dict\n",
    "print(f\"Role (dict syntax): {msg['role']}\")\n",
    "print(f\"Content (dict syntax): {msg['content']}\")\n",
    "\n",
    "# Access like an object\n",
    "print(f\"Role (object syntax): {msg.role}\")\n",
    "print(f\"Content (object syntax): {msg.content}\")\n",
    "\n",
    "# Use .get() method (like dict)\n",
    "print(f\"Name (with default): {msg.get('name', 'Anonymous')}\")\n",
    "\n",
    "# Convert to dict\n",
    "msg_dict = msg.model_dump()\n",
    "print(f\"\\nAs dictionary: {msg_dict}\")\n",
    "print(f\"Type: {type(msg_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Dict Compatibility?\n",
    "\n",
    "This dual interface allows you to:\n",
    "1. Use dictionary syntax when working with message lists\n",
    "2. Use object syntax for cleaner code\n",
    "3. Easily serialize to JSON\n",
    "4. Maintain backward compatibility\n",
    "\n",
    "**In practice, you'll see both styles:**\n",
    "```python\n",
    "# Simple dict style (common in examples)\n",
    "messages = [{'role': 'user', 'content': 'Hi'}]\n",
    "\n",
    "# Message object style (more features)\n",
    "messages = [Message(role='user', content='Hi')]\n",
    "\n",
    "# Both work! Qwen-Agent handles conversion internally\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: The `content` Field - Simple Text\n",
    "\n",
    "### Content can be a string:\n",
    "\n",
    "```python\n",
    "content: Union[str, List[ContentItem]]\n",
    "```\n",
    "\n",
    "For simple text-only messages, `content` is just a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple text content\n",
    "simple_msg = Message(\n",
    "    role='user',\n",
    "    content='What is the capital of France?'\n",
    ")\n",
    "\n",
    "print(f\"Content type: {type(simple_msg.content)}\")\n",
    "print(f\"Content value: {simple_msg.content}\")\n",
    "\n",
    "# Multi-line text content\n",
    "multiline_msg = Message(\n",
    "    role='user',\n",
    "    content=\"\"\"Please help me with:\n",
    "    1. Understanding Python decorators\n",
    "    2. Writing better code\n",
    "    3. Optimizing performance\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(f\"\\nMultiline content:\\n{multiline_msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: The `ContentItem` Class - Multimodal Content\n",
    "\n",
    "### Source Code Location:\n",
    "`/qwen_agent/llm/schema.py` (lines 80-130)\n",
    "\n",
    "### ContentItem Definition:\n",
    "\n",
    "```python\n",
    "class ContentItem(BaseModelCompatibleDict):\n",
    "    text: Optional[str] = None\n",
    "    image: Optional[str] = None          # URL or base64\n",
    "    file: Optional[str] = None           # File path or URL\n",
    "    audio: Optional[Union[str, dict]] = None\n",
    "    video: Optional[Union[str, list]] = None\n",
    "```\n",
    "\n",
    "### **Important Rule**: Exactly ONE field must be provided\n",
    "\n",
    "The validator (lines 95-111) ensures mutual exclusivity:\n",
    "```python\n",
    "if provided_fields != 1:\n",
    "    raise ValueError(\"Exactly one of 'text', 'image', 'file', 'audio', or 'video' must be provided.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_agent.llm.schema import ContentItem\n",
    "\n",
    "# Example 1: Text ContentItem\n",
    "text_item = ContentItem(text='Hello, world!')\n",
    "print(f\"Text item: {text_item}\")\n",
    "print(f\"Type: {text_item.type}\")\n",
    "print(f\"Value: {text_item.value}\")\n",
    "\n",
    "# Example 2: Image ContentItem (URL)\n",
    "image_item = ContentItem(\n",
    "    image='https://example.com/image.jpg'\n",
    ")\n",
    "print(f\"\\nImage item: {image_item}\")\n",
    "print(f\"Type: {image_item.type}\")\n",
    "print(f\"Value: {image_item.value}\")\n",
    "\n",
    "# Example 3: File ContentItem\n",
    "file_item = ContentItem(\n",
    "    file='/path/to/document.pdf'\n",
    ")\n",
    "print(f\"\\nFile item: {file_item}\")\n",
    "\n",
    "# This would FAIL (can't have both text and image):\n",
    "# bad_item = ContentItem(text='Hello', image='image.jpg')  # ValueError!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful ContentItem Methods:\n",
    "\n",
    "```python\n",
    "item.type          # Returns 'text', 'image', 'file', 'audio', or 'video'\n",
    "item.value         # Returns the actual value (string or dict)\n",
    "item.get_type_and_value()  # Returns tuple (type, value)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate methods\n",
    "item = ContentItem(text='Sample text')\n",
    "\n",
    "print(f\"Type property: {item.type}\")\n",
    "print(f\"Value property: {item.value}\")\n",
    "print(f\"Type and value method: {item.get_type_and_value()}\")\n",
    "\n",
    "# Practical usage: checking content type\n",
    "def process_content(item: ContentItem):\n",
    "    \"\"\"Process different content types\"\"\"\n",
    "    if item.type == 'text':\n",
    "        return f\"Processing text: {item.value[:50]}...\"\n",
    "    elif item.type == 'image':\n",
    "        return f\"Processing image from: {item.value}\"\n",
    "    elif item.type == 'file':\n",
    "        return f\"Processing file: {item.value}\"\n",
    "    else:\n",
    "        return f\"Processing {item.type}\"\n",
    "\n",
    "# Test with different types\n",
    "text_content = ContentItem(text='This is a long piece of text that needs processing')\n",
    "image_content = ContentItem(image='https://example.com/photo.jpg')\n",
    "\n",
    "print(f\"\\n{process_content(text_content)}\")\n",
    "print(process_content(image_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Multimodal Messages - Text + Images\n",
    "\n",
    "### When content is a List[ContentItem]:\n",
    "\n",
    "For messages that combine text and images (like vision models), `content` becomes a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multimodal message (text + image)\n",
    "multimodal_msg = Message(\n",
    "    role='user',\n",
    "    content=[\n",
    "        ContentItem(text='What is in this image?'),\n",
    "        ContentItem(image='https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-VL/demo_small.jpg')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Multimodal Message:\")\n",
    "print(f\"Role: {multimodal_msg.role}\")\n",
    "print(f\"Content type: {type(multimodal_msg.content)}\")\n",
    "print(f\"Number of items: {len(multimodal_msg.content)}\")\n",
    "\n",
    "# Iterate through content items\n",
    "for i, item in enumerate(multimodal_msg.content):\n",
    "    print(f\"\\nItem {i}:\")\n",
    "    print(f\"  Type: {item.type}\")\n",
    "    print(f\"  Value: {item.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with a Vision Model (if available):\n",
    "\n",
    "**Note**: This requires a vision-language model like Qwen-VL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with Qwen-VL (uncomment if you have access)\n",
    "from qwen_agent.agents import Assistant\n",
    "\n",
    "# Configure for vision model\n",
    "vl_cfg = {\n",
    "    'model': 'qwen-vl-max',  # Vision-language model\n",
    "    'model_type': 'qwenvl_dashscope'\n",
    "}\n",
    "\n",
    "# Create vision agent\n",
    "# Uncomment to test (requires DashScope access to VL models):\n",
    "# vision_bot = Assistant(llm=vl_cfg)\n",
    "\n",
    "# Create multimodal message\n",
    "# messages = [\n",
    "#     Message(\n",
    "#         role='user',\n",
    "#         content=[\n",
    "#             ContentItem(text='Describe this image in detail'),\n",
    "#             ContentItem(image='https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-VL/demo_small.jpg')\n",
    "#         ]\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# Get response\n",
    "# response = vision_bot.run_nonstream(messages=messages)\n",
    "# for msg in response:\n",
    "#     if msg['role'] == 'assistant':\n",
    "#         print(msg['content'])\n",
    "\n",
    "print(\"Vision model example code ready (commented out).\")\n",
    "print(\"Uncomment to test if you have access to qwen-vl-max.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: The `reasoning_content` Field\n",
    "\n",
    "### What is reasoning_content?\n",
    "\n",
    "Advanced reasoning models (like QwQ-32B) show their \"thinking process\" separately from the final answer.\n",
    "\n",
    "```python\n",
    "class Message:\n",
    "    content: str                      # Final answer\n",
    "    reasoning_content: Optional[str]  # Thinking process\n",
    "```\n",
    "\n",
    "### Example Response Structure:\n",
    "\n",
    "```\n",
    "Message(\n",
    "    role='assistant',\n",
    "    reasoning_content='Let me think... First I need to...',\n",
    "    content='The answer is 42.'\n",
    ")\n",
    "```\n",
    "\n",
    "### Visual Representation:\n",
    "\n",
    "```\n",
    "User: \"Solve 2x + 5 = 15\"\n",
    "\n",
    "Agent:\n",
    "  reasoning_content: \"I need to isolate x.\n",
    "                      First, subtract 5 from both sides: 2x = 10\n",
    "                      Then divide by 2: x = 5\"\n",
    "  \n",
    "  content: \"x = 5\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a reasoning model response\n",
    "reasoning_msg = Message(\n",
    "    role='assistant',\n",
    "    reasoning_content=\"Let me analyze this step by step:\\n1. The question asks about France\\n2. France is in Europe\\n3. The capital is Paris\",\n",
    "    content='The capital of France is Paris.'\n",
    ")\n",
    "\n",
    "print(\"Reasoning Model Response:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n\ud83e\udd14 Thinking Process:\\n{reasoning_msg.reasoning_content}\")\n",
    "print(f\"\\n\ud83d\udca1 Final Answer:\\n{reasoning_msg.content}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if reasoning content exists\n",
    "if reasoning_msg.get('reasoning_content'):\n",
    "    print(\"\\n\u2705 This message includes reasoning!\")\n",
    "else:\n",
    "    print(\"\\n\u274c No reasoning content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use reasoning_content:\n",
    "\n",
    "1. **QwQ-32B and other reasoning models**\n",
    "2. **Complex problem-solving** where showing work is valuable\n",
    "3. **Educational contexts** where explanation matters\n",
    "4. **Debugging agent decisions**\n",
    "\n",
    "For normal models (Qwen-Max, etc.), this field is usually `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: The `FunctionCall` Class (Preview)\n",
    "\n",
    "### Source Code Location:\n",
    "`/qwen_agent/llm/schema.py` (lines 69-78)\n",
    "\n",
    "### FunctionCall Definition:\n",
    "\n",
    "```python\n",
    "class FunctionCall(BaseModelCompatibleDict):\n",
    "    name: str        # Tool name to execute\n",
    "    arguments: str   # JSON string of parameters\n",
    "```\n",
    "\n",
    "### When Agents Use Tools:\n",
    "\n",
    "Instead of generating text, the LLM generates a function call:\n",
    "\n",
    "```\n",
    "User: \"What's the weather in Tokyo?\"\n",
    "\n",
    "Agent generates:\n",
    "  Message(\n",
    "      role='assistant',\n",
    "      content='',\n",
    "      function_call=FunctionCall(\n",
    "          name='weather_api',\n",
    "          arguments='{\"location\": \"Tokyo\"}'\n",
    "      )\n",
    "  )\n",
    "```\n",
    "\n",
    "We'll dive deep into this on **Day 6: Function Calling**. For now, just understand the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_agent.llm.schema import FunctionCall\n",
    "import json\n",
    "\n",
    "# Example 1: Simple function call\n",
    "func_call = FunctionCall(\n",
    "    name='get_weather',\n",
    "    arguments='{\"city\": \"Tokyo\", \"units\": \"celsius\"}'\n",
    ")\n",
    "\n",
    "print(\"Function Call:\")\n",
    "print(f\"Name: {func_call.name}\")\n",
    "print(f\"Arguments (string): {func_call.arguments}\")\n",
    "print(f\"Arguments (parsed): {json.loads(func_call.arguments)}\")\n",
    "\n",
    "# Example 2: Message with function call\n",
    "tool_msg = Message(\n",
    "    role='assistant',\n",
    "    content='',  # Often empty when making function call\n",
    "    function_call=func_call\n",
    ")\n",
    "\n",
    "print(f\"\\nMessage with function call:\")\n",
    "print(tool_msg)\n",
    "\n",
    "# Check if message has function call\n",
    "if tool_msg.get('function_call'):\n",
    "    print(f\"\\n\u2705 Agent wants to use tool: {tool_msg.function_call.name}\")\n",
    "else:\n",
    "    print(\"\\n\u274c No function call in this message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: The `name` Field\n",
    "\n",
    "### Purpose:\n",
    "The `name` field identifies the speaker in specific contexts:\n",
    "\n",
    "1. **Function messages**: Which tool generated this result\n",
    "2. **Multi-agent systems**: Which agent is speaking\n",
    "3. **Named personas**: For role-playing scenarios\n",
    "\n",
    "### Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Function result with name\n",
    "function_result = Message(\n",
    "    role='function',\n",
    "    name='web_search',\n",
    "    content='{\"results\": [\"Tokyo weather: Sunny, 25\u00b0C\"]}'\n",
    ")\n",
    "\n",
    "print(\"Function Result:\")\n",
    "print(f\"Role: {function_result.role}\")\n",
    "print(f\"Name (tool): {function_result.name}\")\n",
    "print(f\"Content: {function_result.content}\")\n",
    "\n",
    "# Example 2: Multi-agent conversation (preview for Day 10)\n",
    "agent1_msg = Message(\n",
    "    role='assistant',\n",
    "    name='CodeExpert',\n",
    "    content='I recommend using a list comprehension for efficiency.'\n",
    ")\n",
    "\n",
    "agent2_msg = Message(\n",
    "    role='assistant',\n",
    "    name='SecurityExpert',\n",
    "    content='Make sure to validate all user inputs first.'\n",
    ")\n",
    "\n",
    "print(f\"\\n{agent1_msg.name}: {agent1_msg.content}\")\n",
    "print(f\"{agent2_msg.name}: {agent2_msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Building Complex Conversations\n",
    "\n",
    "### Realistic Conversation Flow:\n",
    "\n",
    "Let's build a conversation that demonstrates various message types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a realistic conversation\n",
    "conversation = [\n",
    "    # 1. System message sets the context\n",
    "    Message(\n",
    "        role='system',\n",
    "        content='You are a helpful data analyst assistant.'\n",
    "    ),\n",
    "    \n",
    "    # 2. User asks a question\n",
    "    Message(\n",
    "        role='user',\n",
    "        content='I need to analyze sales data from Q1 2024.'\n",
    "    ),\n",
    "    \n",
    "    # 3. Assistant asks for clarification\n",
    "    Message(\n",
    "        role='assistant',\n",
    "        content='I can help with that! What specific metrics are you interested in?'\n",
    "    ),\n",
    "    \n",
    "    # 4. User provides more details\n",
    "    Message(\n",
    "        role='user',\n",
    "        content='Total revenue and top 5 products.'\n",
    "    ),\n",
    "    \n",
    "    # 5. Assistant decides to use a tool (simulated)\n",
    "    Message(\n",
    "        role='assistant',\n",
    "        content='',\n",
    "        function_call=FunctionCall(\n",
    "            name='analyze_sales',\n",
    "            arguments='{\"period\": \"Q1 2024\", \"metrics\": [\"revenue\", \"top_products\"]}'\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    # 6. Tool returns results\n",
    "    Message(\n",
    "        role='function',\n",
    "        name='analyze_sales',\n",
    "        content='{\"total_revenue\": 1250000, \"top_products\": [\"ProductA\", \"ProductB\", \"ProductC\", \"ProductD\", \"ProductE\"]}'\n",
    "    ),\n",
    "    \n",
    "    # 7. Assistant presents results\n",
    "    Message(\n",
    "        role='assistant',\n",
    "        content='Based on the Q1 2024 data:\\n- Total Revenue: $1,250,000\\n- Top 5 Products: ProductA, ProductB, ProductC, ProductD, ProductE'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Display the conversation\n",
    "print(\"Complete Conversation Flow:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, msg in enumerate(conversation, 1):\n",
    "    role_emoji = {\n",
    "        'system': '\u2699\ufe0f',\n",
    "        'user': '\ud83d\udc64',\n",
    "        'assistant': '\ud83e\udd16',\n",
    "        'function': '\ud83d\udd27'\n",
    "    }\n",
    "    \n",
    "    emoji = role_emoji.get(msg.role, '\u2753')\n",
    "    print(f\"\\n{i}. {emoji} {msg.role.upper()}\", end='')\n",
    "    \n",
    "    if msg.get('name'):\n",
    "        print(f\" ({msg.name})\", end='')\n",
    "    print(\":\")\n",
    "    \n",
    "    if msg.get('function_call'):\n",
    "        print(f\"   [Calling tool: {msg.function_call.name}]\")\n",
    "        print(f\"   [Arguments: {msg.function_call.arguments}]\")\n",
    "    elif msg.content:\n",
    "        # Indent content\n",
    "        for line in msg.content.split('\\n'):\n",
    "            print(f\"   {line}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11: Message Utilities\n",
    "\n",
    "### Helper Functions for Working with Messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_messages_by_role(messages, role):\n",
    "    \"\"\"Count messages of a specific role\"\"\"\n",
    "    return sum(1 for msg in messages if msg.get('role') == role)\n",
    "\n",
    "def get_last_user_message(messages):\n",
    "    \"\"\"Get the most recent user message\"\"\"\n",
    "    for msg in reversed(messages):\n",
    "        if msg.get('role') == 'user':\n",
    "            return msg\n",
    "    return None\n",
    "\n",
    "def extract_text_content(message):\n",
    "    \"\"\"Extract text from message content (handles both str and List[ContentItem])\"\"\"\n",
    "    content = message.get('content', '')\n",
    "    \n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "    elif isinstance(content, list):\n",
    "        # Extract text from ContentItems\n",
    "        texts = [item.value for item in content if item.type == 'text']\n",
    "        return ' '.join(texts)\n",
    "    return ''\n",
    "\n",
    "def has_function_call(message):\n",
    "    \"\"\"Check if message contains a function call\"\"\"\n",
    "    return message.get('function_call') is not None\n",
    "\n",
    "def is_multimodal(message):\n",
    "    \"\"\"Check if message contains non-text content\"\"\"\n",
    "    content = message.get('content', '')\n",
    "    if isinstance(content, list):\n",
    "        return any(item.type != 'text' for item in content)\n",
    "    return False\n",
    "\n",
    "# Test the utilities\n",
    "print(\"Message Utilities Demo:\")\n",
    "print(f\"User messages: {count_messages_by_role(conversation, 'user')}\")\n",
    "print(f\"Assistant messages: {count_messages_by_role(conversation, 'assistant')}\")\n",
    "print(f\"Function messages: {count_messages_by_role(conversation, 'function')}\")\n",
    "\n",
    "last_user = get_last_user_message(conversation)\n",
    "if last_user:\n",
    "    print(f\"\\nLast user message: {extract_text_content(last_user)}\")\n",
    "\n",
    "# Check for function calls\n",
    "func_calls = [msg for msg in conversation if has_function_call(msg)]\n",
    "print(f\"\\nMessages with function calls: {len(func_calls)}\")\n",
    "\n",
    "# Create a multimodal message to test\n",
    "mm_msg = Message(\n",
    "    role='user',\n",
    "    content=[\n",
    "        ContentItem(text='Describe this'),\n",
    "        ContentItem(image='image.jpg')\n",
    "    ]\n",
    ")\n",
    "print(f\"Multimodal message: {is_multimodal(mm_msg)}\")\n",
    "print(f\"Text-only message: {is_multimodal(conversation[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12: Working with Real Agents\n",
    "\n",
    "### Sending and Receiving Messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from qwen_agent.agents import Assistant\n\n# Create agent using llm_cfg from cell 4 (Fireworks API)\nbot = Assistant(llm=llm_cfg)\n\n# Build messages using Message objects\nmessages = [\n    Message(\n        role='system',\n        content='You are a concise assistant. Keep responses under 50 words.'\n    ),\n    Message(\n        role='user',\n        content='Explain what a REST API is.'\n    )\n]\n\nprint(\"Sending messages to agent...\\n\")\n\n# Get response (collect all streaming responses)\nresponse = None\nfor resp in bot.run(messages=messages):\n    response = resp\n\n# Examine the response structure\nprint(\"Response Analysis:\")\nprint(f\"Response type: {type(response)}\")\nprint(f\"Number of messages: {len(response)}\")\n\nfor i, msg in enumerate(response):\n    print(f\"\\nMessage {i}:\")\n    print(f\"  Role: {msg.get('role')}\")\n    print(f\"  Content type: {type(msg.get('content'))}\")\n    \n    if msg.get('role') == 'assistant':\n        content = extract_text_content(msg)\n        # Show just the last 200 chars (thinking model may have long responses)\n        if len(content) > 200:\n            print(f\"  Content (excerpt): ...{content[-200:]}\")\n        else:\n            print(f\"  Content: {content}\")\n        print(f\"  Word count: {len(content.split())}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 13: Message Serialization\n",
    "\n",
    "### Converting Messages to/from JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a message\n",
    "msg = Message(\n",
    "    role='user',\n",
    "    content='Hello, world!',\n",
    "    extra={'timestamp': '2024-01-15T10:30:00'}\n",
    ")\n",
    "\n",
    "# Method 1: model_dump() - to dict\n",
    "msg_dict = msg.model_dump()\n",
    "print(\"As dictionary:\")\n",
    "print(msg_dict)\n",
    "\n",
    "# Method 2: model_dump_json() - to JSON string\n",
    "msg_json = msg.model_dump_json()\n",
    "print(\"\\nAs JSON string:\")\n",
    "print(msg_json)\n",
    "\n",
    "# Method 3: Manual JSON serialization\n",
    "msg_json_manual = json.dumps(msg.model_dump(), indent=2)\n",
    "print(\"\\nAs formatted JSON:\")\n",
    "print(msg_json_manual)\n",
    "\n",
    "# Deserialize back to Message\n",
    "loaded_dict = json.loads(msg_json)\n",
    "reconstructed_msg = Message(**loaded_dict)\n",
    "print(\"\\nReconstructed message:\")\n",
    "print(reconstructed_msg)\n",
    "print(f\"Equal to original: {msg.model_dump() == reconstructed_msg.model_dump()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving/Loading Conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a conversation\n",
    "convo = [\n",
    "    Message(role='user', content='Hi there!'),\n",
    "    Message(role='assistant', content='Hello! How can I help?'),\n",
    "    Message(role='user', content='Tell me a joke.'),\n",
    "]\n",
    "\n",
    "# Save to file\n",
    "def save_conversation(messages, filename):\n",
    "    \"\"\"Save conversation to JSON file\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(\n",
    "            [msg.model_dump() for msg in messages],\n",
    "            f,\n",
    "            indent=2\n",
    "        )\n",
    "\n",
    "def load_conversation(filename):\n",
    "    \"\"\"Load conversation from JSON file\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        return [Message(**msg_dict) for msg_dict in data]\n",
    "\n",
    "# Save\n",
    "save_conversation(convo, 'conversation.json')\n",
    "print(\"\u2705 Conversation saved to conversation.json\")\n",
    "\n",
    "# Load\n",
    "loaded_convo = load_conversation('conversation.json')\n",
    "print(f\"\u2705 Loaded {len(loaded_convo)} messages\")\n",
    "\n",
    "for msg in loaded_convo:\n",
    "    print(f\"  {msg.role}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n## \ud83c\udfaf Summary of Real Examples\n\nYou've now seen **ACTUAL working code** with **REAL outputs** showing:\n\n### \u2705 What We Covered:\n\n1. **Real Fireworks API Calls**\n   - Qwen3-235B-Thinking model in action\n   - Understanding how reasoning appears in responses\n   - API response structure analysis\n\n2. **Multimodal Messages**\n   - Combining text + images with `ContentItem`\n   - Real image URLs from Qwen's demo dataset\n   - Serialization/deserialization of complex messages\n\n3. **Extra Field Metadata**\n   - Storing custom data (timestamps, user IDs, etc.)\n   - Real-world metadata patterns\n   - Perfect serialization support\n\n4. **Complete Multi-Turn Conversation**\n   - Building conversation history\n   - Passing full context to LLM\n   - How assistant remembers previous messages\n\n### \ud83d\udca1 Key Insights:\n\n| Feature | With Fireworks API | With Native Qwen (DashScope) |\n|---------|-------------------|------------------------------|\n| **Thinking Model** | Reasoning in `content` field | Separate `reasoning_content` |\n| **Message Format** | Standard OpenAI-compatible | Full Qwen schema support |\n| **Multimodal** | Text + metadata only | Text + images + video + audio |\n\n### \ud83d\ude80 You're Now Ready To:\n\n- \u2705 Build complex conversations with proper message structure\n- \u2705 Handle multimodal content (text, images, files)\n- \u2705 Extract and use metadata from messages\n- \u2705 Work with thinking models and their reasoning output\n- \u2705 Serialize/deserialize messages for storage\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ========================================\n# EXAMPLE 4: Complete Multi-Turn Conversation\n# ========================================\n# This shows how messages flow in a REAL conversation\n\nprint(\"\ud83d\udd04 COMPLETE MULTI-TURN CONVERSATION\")\nprint(\"=\"*70)\n\n# Start with empty conversation\nconversation = []\n\n# Turn 1: System message\nconversation.append(Message(\n    role='system',\n    content='You are a helpful assistant. Keep responses under 30 words.'\n))\n\n# Turn 2: User asks first question\nconversation.append(Message(\n    role='user',\n    content='What is 15 * 23?'\n))\n\nprint(\"\\n\ud83d\udc64 USER: What is 15 * 23?\")\nprint(\"\u23f3 Calling API...\")\n\n# Get response from LLM\nllm_short = get_chat_model({\n    'model': 'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507',\n    'model_server': 'https://api.fireworks.ai/inference/v1',\n    'api_key': os.environ['FIREWORKS_API_KEY'],\n    'generate_cfg': {'max_tokens': 200, 'temperature': 0.6}\n})\n\nresponses = []\nfor resp in llm_short.chat(messages=conversation):\n    responses = resp\n\n# Add assistant response to conversation\nconversation.extend(responses)\n\nassistant_msg = responses[-1]\nprint(f\"\ud83e\udd16 ASSISTANT: {assistant_msg['content'][:100]}...\")\n\n# Turn 3: User asks follow-up\nconversation.append(Message(\n    role='user',\n    content='Now multiply that by 2'\n))\n\nprint(f\"\\n\ud83d\udc64 USER: Now multiply that by 2\")\nprint(\"\u23f3 Calling API with full context...\")\n\n# Get second response (with full history)\nresponses2 = []\nfor resp in llm_short.chat(messages=conversation):\n    responses2 = resp\n\nconversation.extend(responses2)\n\nassistant_msg2 = responses2[-1]\nprint(f\"\ud83e\udd16 ASSISTANT: {assistant_msg2['content'][:100]}...\")\n\n# Show conversation structure\nprint(f\"\\n\ud83d\udcca FINAL CONVERSATION STATE:\")\nprint(f\"   Total messages: {len(conversation)}\")\nfor i, msg in enumerate(conversation):\n    role_emoji = {'system': '\u2699\ufe0f', 'user': '\ud83d\udc64', 'assistant': '\ud83e\udd16'}\n    emoji = role_emoji.get(msg.get('role'), '\u2753')\n    content_preview = msg.get('content', '')[:50]\n    print(f\"   {i+1}. {emoji} {msg.get('role')}: {content_preview}...\")\n\nprint(\"\\n\u2705 Multi-turn conversation complete!\")\nprint(\"\ud83d\udca1 Key takeaway: Each API call receives the FULL conversation history\")",
   "metadata": {},
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udd04 COMPLETE MULTI-TURN CONVERSATION\n",
      "======================================================================\n",
      "\n",
      "\ud83d\udc64 USER: What is 15 * 23?\n",
      "\u23f3 Calling API...\n",
      "\ud83e\udd16 ASSISTANT: Okay, the user is asking for the product of 15 and 23. Let me calculate that. 15 times 20 is 300, an...\n",
      "\n",
      "\ud83d\udc64 USER: Now multiply that by 2\n",
      "\u23f3 Calling API with full context...\n",
      "\ud83e\udd16 ASSISTANT: Okay, the user just asked to multiply the previous result by 2. Last time I calculated 15 * 23 = 345...\n",
      "\n",
      "\ud83d\udcca FINAL CONVERSATION STATE:\n",
      "   Total messages: 5\n",
      "   1. \u2699\ufe0f system: You are a helpful assistant. Keep responses under ...\n",
      "   2. \ud83d\udc64 user: What is 15 * 23?...\n",
      "   3. \ud83e\udd16 assistant: Okay, the user is asking for the product of 15 and...\n",
      "   4. \ud83d\udc64 user: Now multiply that by 2...\n",
      "   5. \ud83e\udd16 assistant: Okay, the user just asked to multiply the previous...\n",
      "\n",
      "\u2705 Multi-turn conversation complete!\n",
      "\ud83d\udca1 Key takeaway: Each API call receives the FULL conversation history\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# ========================================\n# EXAMPLE 3: Using the `extra` Field for Metadata\n# ========================================\nfrom datetime import datetime\n\n# The `extra` field can store ANY additional metadata\nmsg_with_metadata = Message(\n    role='user',\n    content='What is the weather today?',\n    extra={\n        'timestamp': datetime.now().isoformat(),\n        'user_id': 'user_12345',\n        'session_id': 'session_abc',\n        'ip_address': '192.168.1.1',\n        'language': 'en',\n        'app_version': '1.2.3',\n        'custom_data': {\n            'priority': 'high',\n            'category': 'weather',\n            'tags': ['urgent', 'forecast']\n        }\n    }\n)\n\nprint(\"\ud83c\udff7\ufe0f  EXTRA FIELD - METADATA EXAMPLE\")\nprint(\"=\"*70)\nprint(f\"\\nMessage role: {msg_with_metadata.role}\")\nprint(f\"Message content: {msg_with_metadata.content}\")\nprint(f\"\\n\ud83d\udccb Extra metadata:\")\nprint(json.dumps(msg_with_metadata.extra, indent=2))\n\n# Access extra fields\nprint(f\"\\n\ud83d\udd0d Accessing extra fields:\")\nprint(f\"   User ID: {msg_with_metadata.extra['user_id']}\")\nprint(f\"   Timestamp: {msg_with_metadata.extra['timestamp']}\")\nprint(f\"   Priority: {msg_with_metadata.extra['custom_data']['priority']}\")\n\n# Use cases for extra field:\nprint(f\"\\n\ud83d\udca1 Common uses for `extra` field:\")\nprint(\"   \u2022 Timestamps for logging\")\nprint(\"   \u2022 User/session tracking\")\nprint(\"   \u2022 A/B testing flags\")\nprint(\"   \u2022 Custom application data\")\nprint(\"   \u2022 Debugging information\")\nprint(\"   \u2022 Analytics metadata\")\n\n# Serialize with extra\nserialized = msg_with_metadata.model_dump()\nprint(f\"\\n\u2705 Serializes perfectly with all metadata intact\")\nprint(f\"   Total fields in serialized: {len(serialized)}\")",
   "metadata": {},
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83c\udff7\ufe0f  EXTRA FIELD - METADATA EXAMPLE\n",
      "======================================================================\n",
      "\n",
      "Message role: user\n",
      "Message content: What is the weather today?\n",
      "\n",
      "\ud83d\udccb Extra metadata:\n",
      "{\n",
      "  \"timestamp\": \"2025-11-13T23:15:37.777698\",\n",
      "  \"user_id\": \"user_12345\",\n",
      "  \"session_id\": \"session_abc\",\n",
      "  \"ip_address\": \"192.168.1.1\",\n",
      "  \"language\": \"en\",\n",
      "  \"app_version\": \"1.2.3\",\n",
      "  \"custom_data\": {\n",
      "    \"priority\": \"high\",\n",
      "    \"category\": \"weather\",\n",
      "    \"tags\": [\n",
      "      \"urgent\",\n",
      "      \"forecast\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "\ud83d\udd0d Accessing extra fields:\n",
      "   User ID: user_12345\n",
      "   Timestamp: 2025-11-13T23:15:37.777698\n",
      "   Priority: high\n",
      "\n",
      "\ud83d\udca1 Common uses for `extra` field:\n",
      "   \u2022 Timestamps for logging\n",
      "   \u2022 User/session tracking\n",
      "   \u2022 A/B testing flags\n",
      "   \u2022 Custom application data\n",
      "   \u2022 Debugging information\n",
      "   \u2022 Analytics metadata\n",
      "\n",
      "\u2705 Serializes perfectly with all metadata intact\n",
      "   Total fields in serialized: 3\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# ========================================\n# EXAMPLE 2: Multimodal Messages with REAL Images\n# ========================================\nfrom qwen_agent.llm.schema import Message, ContentItem\n\n# Using a REAL publicly accessible image\nreal_image_url = 'https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-VL/demo_small.jpg'\n\n# Create multimodal message\nmultimodal_msg = Message(\n    role='user',\n    content=[\n        ContentItem(text='What objects do you see in this image?'),\n        ContentItem(image=real_image_url)\n    ]\n)\n\nprint(\"\ud83d\uddbc\ufe0f  MULTIMODAL MESSAGE EXAMPLE\")\nprint(\"=\"*70)\nprint(f\"\\nRole: {multimodal_msg.role}\")\nprint(f\"Content is a list: {isinstance(multimodal_msg.content, list)}\")\nprint(f\"Number of content items: {len(multimodal_msg.content)}\")\n\nfor i, item in enumerate(multimodal_msg.content):\n    print(f\"\\n\ud83d\udccc Item {i}:\")\n    print(f\"   Type: {item.type}\")\n    if item.type == 'text':\n        print(f\"   Text: {item.value}\")\n    elif item.type == 'image':\n        print(f\"   Image URL: {item.value}\")\n        print(f\"   URL length: {len(item.value)} chars\")\n\n# Show how to serialize/deserialize\nmsg_dict = multimodal_msg.model_dump()\nprint(f\"\\n\ud83d\udce6 Serialized to dict:\")\nprint(json.dumps(msg_dict, indent=2)[:400] + \"...\")\n\n# Reconstruct from dict\nreconstructed = Message(**msg_dict)\nprint(f\"\\n\u2705 Successfully reconstructed from dict\")\nprint(f\"   Equal to original: {msg_dict == reconstructed.model_dump()}\")",
   "metadata": {},
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\uddbc\ufe0f  MULTIMODAL MESSAGE EXAMPLE\n",
      "======================================================================\n",
      "\n",
      "Role: user\n",
      "Content is a list: True\n",
      "Number of content items: 2\n",
      "\n",
      "\ud83d\udccc Item 0:\n",
      "   Type: text\n",
      "   Text: What objects do you see in this image?\n",
      "\n",
      "\ud83d\udccc Item 1:\n",
      "   Type: image\n",
      "   Image URL: https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-VL/demo_small.jpg\n",
      "   URL length: 71 chars\n",
      "\n",
      "\ud83d\udce6 Serialized to dict:\n",
      "{\n",
      "  \"role\": \"user\",\n",
      "  \"content\": [\n",
      "    {\n",
      "      \"text\": \"What objects do you see in this image?\"\n",
      "    },\n",
      "    {\n",
      "      \"image\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-VL/demo_small.jpg\"\n",
      "    }\n",
      "  ]\n",
      "}...\n",
      "\n",
      "\u2705 Successfully reconstructed from dict\n",
      "   Equal to original: True\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### \ud83d\udcdd Important Finding: reasoning_content with Fireworks API\n\n**Key Discovery**: The Qwen3-235B-Thinking model on Fireworks API includes reasoning **within the `content` field**, NOT as separate `reasoning_content`.\n\n```python\n# What we get:\nMessage(\n    role='assistant',\n    content='Let me think... [reasoning] ... The answer is 4 books.'  # All in one\n    reasoning_content=None  # \u274c Not populated\n)\n\n# vs. Native Qwen API (DashScope):\nMessage(\n    role='assistant',\n    reasoning_content='Let me think... [step by step]',  # \u2705 Separate\n    content='The answer is 4 books.'\n)\n```\n\nThis is an **API implementation difference**, not a bug. The thinking is still there - just formatted differently!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ========================================\n# EXAMPLE 1: Real API Call with Thinking Model\n# ========================================\nfrom qwen_agent.llm import get_chat_model\nfrom qwen_agent.llm.schema import Message\nimport json\n\n# Configure with SHORT max_tokens to see concise output\nllm_cfg_short = {\n    'model': 'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507',\n    'model_server': 'https://api.fireworks.ai/inference/v1',\n    'api_key': os.environ['FIREWORKS_API_KEY'],\n    'generate_cfg': {\n        'max_tokens': 500,  # Shorter for demo\n        'temperature': 0.6,\n    }\n}\n\n# Get LLM instance\nllm = get_chat_model(llm_cfg_short)\n\n# Create a simple math problem\nmessages = [\n    {'role': 'system', 'content': 'You are a helpful math tutor. Explain your reasoning step by step.'},\n    {'role': 'user', 'content': 'Solve: If a book costs $12 and I have $50, how many books can I buy?'}\n]\n\nprint(\"\ud83d\udd25 Making REAL API call to Fireworks...\")\nprint(\"Question: If a book costs $12 and I have $50, how many books can I buy?\")\nprint(\"\\n\" + \"=\"*70)\n\n# Call the API\nresponses = []\nfor response in llm.chat(messages=messages, stream=True):\n    responses = response\n\n# Extract the final message\nif responses:\n    final_msg = responses[-1]\n    \n    print(\"\\n\ud83d\udcca RESPONSE STRUCTURE:\")\n    print(f\"  Role: {final_msg.get('role')}\")\n    print(f\"  Has content: {bool(final_msg.get('content'))}\")\n    print(f\"  Has reasoning_content: {bool(final_msg.get('reasoning_content'))}\")\n    print(f\"  Content type: {type(final_msg.get('content'))}\")\n    \n    # Show reasoning if present\n    if final_msg.get('reasoning_content'):\n        reasoning = final_msg['reasoning_content']\n        print(f\"\\n\ud83e\udd14 THINKING PROCESS ({len(reasoning)} chars):\")\n        print(\"\u2500\" * 70)\n        print(reasoning[:500] + \"...\" if len(reasoning) > 500 else reasoning)\n    \n    # Show final answer\n    if final_msg.get('content'):\n        content = final_msg['content']\n        print(f\"\\n\ud83d\udca1 FINAL ANSWER ({len(content)} chars):\")\n        print(\"\u2500\" * 70)\n        print(content[:300] + \"...\" if len(content) > 300 else content)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"\u2705 Real API call complete!\")",
   "metadata": {},
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ud83d\udd25 Making REAL API call to Fireworks...\n",
      "Question: If a book costs $12 and I have $50, how many books can I buy?\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\ud83d\udcca RESPONSE STRUCTURE:\n",
      "  Role: assistant\n",
      "  Has content: True\n",
      "  Has reasoning_content: False\n",
      "  Content type: <class 'str'>\n",
      "\n",
      "\ud83d\udca1 FINAL ANSWER (864 chars):\n",
      "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
      "Okay, let's see. The problem is: If a book costs $12 and I have $50, how many books can I buy? Alright, so I need to figure out how many times 12 goes into 50. That sounds like a division problem. Let me write that down.\n",
      "\n",
      "First, total money I have is $50. Each book is $12. So the number of books I c...\n",
      "\n",
      "======================================================================\n",
      "\u2705 Real API call complete!\n",
      "\n",
      "\ud83d\udd0d Full response keys: ['role', 'content']\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n## \ud83d\udd25 Part 15: REAL EXAMPLES with Fireworks Thinking Model\n\n### Now let's see ACTUAL API calls and REAL outputs!\n\nThis section demonstrates:\n1. \u2705 **Real Fireworks API calls** with Qwen3-235B-Thinking\n2. \u2705 **Actual reasoning extraction** from thinking models\n3. \u2705 **How to pass reasoning** back in conversations\n4. \u2705 **Multimodal messages** with real images\n5. \u2705 **Message extra fields** and metadata\n6. \u2705 **Complete conversation** with all message types\n\nAll cells below have **saved outputs** so you can see exactly what happens!",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 14: Practice Exercises\n",
    "\n",
    "### Exercise 1: Create a Multimodal Message\n",
    "Build a message that combines text and an image URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a multimodal message\n",
    "# Requirements:\n",
    "# 1. Use ContentItem for both text and image\n",
    "# 2. Text should ask a question about the image\n",
    "# 3. Image URL can be any valid URL\n",
    "\n",
    "# Your code here:\n",
    "multimodal_exercise = None\n",
    "\n",
    "# Test:\n",
    "# print(multimodal_exercise)\n",
    "# print(f\"Is multimodal: {is_multimodal(multimodal_exercise)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Build a Conversation Parser\n",
    "Create a function that analyzes a conversation and returns statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement conversation_stats()\n",
    "# Should return:\n",
    "# - Total messages\n",
    "# - Messages per role\n",
    "# - Number of function calls\n",
    "# - Average message length\n",
    "# - Has system message?\n",
    "\n",
    "def conversation_stats(messages):\n",
    "    \"\"\"Analyze a conversation\"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test with the conversation we built earlier:\n",
    "# stats = conversation_stats(conversation)\n",
    "# print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Message Filter\n",
    "Filter a conversation to show only specific types of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement message filters\n",
    "\n",
    "def filter_by_role(messages, role):\n",
    "    \"\"\"Return only messages with specific role\"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "def filter_function_calls(messages):\n",
    "    \"\"\"Return only messages with function calls\"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "def filter_multimodal(messages):\n",
    "    \"\"\"Return only multimodal messages\"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test:\n",
    "# user_msgs = filter_by_role(conversation, 'user')\n",
    "# print(f\"User messages: {len(user_msgs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 15: Key Takeaways\n",
    "\n",
    "### What You Learned Today:\n",
    "\n",
    "1. **Message Structure**\n",
    "   - `role`: Who is speaking (system/user/assistant/function)\n",
    "   - `content`: What is being said (str or List[ContentItem])\n",
    "   - `reasoning_content`: Thinking process (for reasoning models)\n",
    "   - `name`: Speaker identifier\n",
    "   - `function_call`: Tool invocation data\n",
    "   - `extra`: Additional metadata\n",
    "\n",
    "2. **ContentItem for Multimodal**\n",
    "   - Exactly ONE of: text, image, file, audio, video\n",
    "   - Use `.type` and `.value` properties\n",
    "   - Combine in lists for multimodal messages\n",
    "\n",
    "3. **FunctionCall Structure**\n",
    "   - `name`: Tool to execute\n",
    "   - `arguments`: JSON string parameters\n",
    "   - Enables agent tool use\n",
    "\n",
    "4. **Message Utilities**\n",
    "   - Dict-compatible interface\n",
    "   - Serialization to/from JSON\n",
    "   - Helper functions for analysis\n",
    "\n",
    "### Common Patterns:\n",
    "\n",
    "```python\n",
    "# Pattern 1: Simple text message\n",
    "msg = Message(role='user', content='Hello')\n",
    "\n",
    "# Pattern 2: Multimodal message\n",
    "msg = Message(\n",
    "    role='user',\n",
    "    content=[\n",
    "        ContentItem(text='What is this?'),\n",
    "        ContentItem(image='url')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pattern 3: Function call message\n",
    "msg = Message(\n",
    "    role='assistant',\n",
    "    content='',\n",
    "    function_call=FunctionCall(name='tool', arguments='{}')\n",
    ")\n",
    "\n",
    "# Pattern 4: Function result message\n",
    "msg = Message(\n",
    "    role='function',\n",
    "    name='tool_name',\n",
    "    content='result data'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 16: Next Steps\n",
    "\n",
    "### Tomorrow (Day 3): LLM Integration\n",
    "We'll explore:\n",
    "- BaseChatModel interface\n",
    "- Different model backends (DashScope, vLLM, Ollama)\n",
    "- Generation parameters\n",
    "- Streaming internals\n",
    "- Token management\n",
    "- Direct LLM usage (without agents)\n",
    "\n",
    "### Homework:\n",
    "1. Create a conversation with at least 5 turns\n",
    "2. Build a multimodal message with your own image\n",
    "3. Implement the exercise functions above\n",
    "4. Read the source: `/qwen_agent/llm/schema.py`\n",
    "5. Experiment with reasoning_content (if you have QwQ access)\n",
    "\n",
    "### Resources:\n",
    "- [Schema Source Code](../qwen_agent/llm/schema.py)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/) - Message uses Pydantic\n",
    "- [OpenAI Message Format](https://platform.openai.com/docs/api-reference/chat) - Similar structure\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udf89 Day 2 Complete!\n",
    "\n",
    "You now understand:\n",
    "- \u2705 Message structure and fields\n",
    "- \u2705 Role types and their purposes\n",
    "- \u2705 ContentItem for multimodal content\n",
    "- \u2705 FunctionCall basics\n",
    "- \u2705 Message serialization and utilities\n",
    "\n",
    "See you tomorrow for Day 3! \ud83d\ude80"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}