{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: Message Schema & Communication\n",
    "\n",
    "## Understanding How Agents Communicate\n",
    "\n",
    "### Today's Learning Objectives:\n",
    "1. Deep dive into the `Message` class structure\n",
    "2. Understand different role types and their purposes\n",
    "3. Work with `ContentItem` for multimodal messages\n",
    "4. Learn about `FunctionCall` messages (preview for Day 6)\n",
    "5. Build complex, multi-modal conversation histories\n",
    "6. Understand reasoning_content for advanced models\n",
    "\n",
    "### Prerequisites:\n",
    "- Completed Day 1\n",
    "- Qwen-Agent installed and configured\n",
    "- API key set up\n",
    "\n",
    "### Time Required: 1.5-2 hours\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Why Messages Matter\n",
    "\n",
    "### The Communication Protocol\n",
    "\n",
    "Everything in Qwen-Agent flows through **Messages**. They are:\n",
    "- The **input** to agents (what you say)\n",
    "- The **output** from agents (what they respond)\n",
    "- The **history** of conversations (context)\n",
    "- The **mechanism** for tool calls (function execution)\n",
    "\n",
    "### Message Flow Diagram:\n",
    "\n",
    "```\n",
    "User Creates Message\n",
    "        |\n",
    "        v\n",
    "[Message(role='user', content='...')]\n",
    "        |\n",
    "        v\n",
    "    Agent.run(messages)\n",
    "        |\n",
    "        v\n",
    "    LLM processes\n",
    "        |\n",
    "        v\n",
    "[Message(role='assistant', content='...'),\n",
    " Message(role='assistant', function_call=...)]\n",
    "        |\n",
    "        v\n",
    "    User receives response\n",
    "```\n",
    "\n",
    "### Key Insight:\n",
    "Messages are **NOT** just strings. They are structured data with:\n",
    "- **role**: Who is speaking\n",
    "- **content**: What is being said (can be text, image, etc.)\n",
    "- **metadata**: Additional information (name, function calls, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Message Class Structure\n",
    "\n",
    "### Source Code Location:\n",
    "`/qwen_agent/llm/schema.py` (lines 132-165)\n",
    "\n",
    "### Message Class Definition:\n",
    "\n",
    "```python\n",
    "class Message(BaseModelCompatibleDict):\n",
    "    role: str                                      # Required: 'user', 'assistant', 'system', 'function'\n",
    "    content: Union[str, List[ContentItem]]         # Required: Message content\n",
    "    reasoning_content: Optional[Union[str, List[ContentItem]]] = None  # For reasoning models\n",
    "    name: Optional[str] = None                     # Agent/tool name\n",
    "    function_call: Optional[FunctionCall] = None   # Tool invocation data\n",
    "    extra: Optional[dict] = None                   # Additional metadata\n",
    "```\n",
    "\n",
    "Let's explore each field in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: The `role` Field\n",
    "\n",
    "### Four Role Types (from schema.py lines 26-29):\n",
    "\n",
    "```python\n",
    "SYSTEM = 'system'      # Instructions for the agent\n",
    "USER = 'user'          # Input from human/user\n",
    "ASSISTANT = 'assistant'  # Response from agent/LLM\n",
    "FUNCTION = 'function'   # Tool execution results\n",
    "```\n",
    "\n",
    "### Role Descriptions:\n",
    "\n",
    "| Role | Purpose | Who Creates It | Example |\n",
    "|------|---------|----------------|----------|\n",
    "| `system` | Give instructions/context to agent | Developer | \"You are a helpful assistant\" |\n",
    "| `user` | User queries and inputs | User/Application | \"What's the weather?\" |\n",
    "| `assistant` | Agent responses | Agent/LLM | \"The weather is sunny\" |\n",
    "| `function` | Tool execution results | Agent (after running tool) | `{\"temperature\": 72}` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# FIREWORKS API CONFIGURATION\n",
    "# ================================================\n",
    "import os\n",
    "\n",
    "# Set API credentials\n",
    "os.environ['FIREWORKS_API_KEY'] = 'fw_3ZTLPrnEtuscTUPYy3sYx3ag'\n",
    "\n",
    "# Standard configuration for Fireworks Qwen3-235B-A22B-Thinking\n",
    "llm_cfg_fireworks = {\n",
    "    'model': 'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507',\n",
    "    'model_server': 'https://api.fireworks.ai/inference/v1',\n",
    "    'api_key': os.environ['FIREWORKS_API_KEY'],\n",
    "    'generate_cfg': {\n",
    "        'max_tokens': 32768,\n",
    "        'temperature': 0.6,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use this as default llm_cfg\n",
    "llm_cfg = llm_cfg_fireworks\n",
    "\n",
    "print('âœ… Configured for Fireworks API')\n",
    "print(f'   Model: Qwen3-235B-A22B-Thinking-2507')\n",
    "print(f'   Max tokens: 32,768')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Message class\n",
    "from qwen_agent.llm.schema import Message, SYSTEM, USER, ASSISTANT, FUNCTION\n",
    "\n",
    "# Example 1: System message\n",
    "system_msg = Message(\n",
    "    role=SYSTEM,\n",
    "    content='You are a helpful AI assistant specialized in Python programming.'\n",
    ")\n",
    "\n",
    "# Example 2: User message\n",
    "user_msg = Message(\n",
    "    role=USER,\n",
    "    content='How do I read a file in Python?'\n",
    ")\n",
    "\n",
    "# Example 3: Assistant message\n",
    "assistant_msg = Message(\n",
    "    role=ASSISTANT,\n",
    "    content='You can use the `open()` function with a context manager...'\n",
    ")\n",
    "\n",
    "# Example 4: Function message (we'll learn more about this on Day 6)\n",
    "function_msg = Message(\n",
    "    role=FUNCTION,\n",
    "    content='{\"result\": \"File read successfully\"}',\n",
    "    name='read_file'  # Name of the tool that was executed\n",
    ")\n",
    "\n",
    "print(\"System Message:\")\n",
    "print(system_msg)\n",
    "print(\"\\nUser Message:\")\n",
    "print(user_msg)\n",
    "print(\"\\nAssistant Message:\")\n",
    "print(assistant_msg)\n",
    "print(\"\\nFunction Message:\")\n",
    "print(function_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message as Dict:\n",
    "\n",
    "The `Message` class extends `BaseModelCompatibleDict`, which means you can use it like a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a message\n",
    "msg = Message(role='user', content='Hello!')\n",
    "\n",
    "# Access like a dict\n",
    "print(f\"Role (dict syntax): {msg['role']}\")\n",
    "print(f\"Content (dict syntax): {msg['content']}\")\n",
    "\n",
    "# Access like an object\n",
    "print(f\"Role (object syntax): {msg.role}\")\n",
    "print(f\"Content (object syntax): {msg.content}\")\n",
    "\n",
    "# Use .get() method (like dict)\n",
    "print(f\"Name (with default): {msg.get('name', 'Anonymous')}\")\n",
    "\n",
    "# Convert to dict\n",
    "msg_dict = msg.model_dump()\n",
    "print(f\"\\nAs dictionary: {msg_dict}\")\n",
    "print(f\"Type: {type(msg_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Dict Compatibility?\n",
    "\n",
    "This dual interface allows you to:\n",
    "1. Use dictionary syntax when working with message lists\n",
    "2. Use object syntax for cleaner code\n",
    "3. Easily serialize to JSON\n",
    "4. Maintain backward compatibility\n",
    "\n",
    "**In practice, you'll see both styles:**\n",
    "```python\n",
    "# Simple dict style (common in examples)\n",
    "messages = [{'role': 'user', 'content': 'Hi'}]\n",
    "\n",
    "# Message object style (more features)\n",
    "messages = [Message(role='user', content='Hi')]\n",
    "\n",
    "# Both work! Qwen-Agent handles conversion internally\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: The `content` Field - Simple Text\n",
    "\n",
    "### Content can be a string:\n",
    "\n",
    "```python\n",
    "content: Union[str, List[ContentItem]]\n",
    "```\n",
    "\n",
    "For simple text-only messages, `content` is just a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple text content\n",
    "simple_msg = Message(\n",
    "    role='user',\n",
    "    content='What is the capital of France?'\n",
    ")\n",
    "\n",
    "print(f\"Content type: {type(simple_msg.content)}\")\n",
    "print(f\"Content value: {simple_msg.content}\")\n",
    "\n",
    "# Multi-line text content\n",
    "multiline_msg = Message(\n",
    "    role='user',\n",
    "    content=\"\"\"Please help me with:\n",
    "    1. Understanding Python decorators\n",
    "    2. Writing better code\n",
    "    3. Optimizing performance\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(f\"\\nMultiline content:\\n{multiline_msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: The `ContentItem` Class - Multimodal Content\n",
    "\n",
    "### Source Code Location:\n",
    "`/qwen_agent/llm/schema.py` (lines 80-130)\n",
    "\n",
    "### ContentItem Definition:\n",
    "\n",
    "```python\n",
    "class ContentItem(BaseModelCompatibleDict):\n",
    "    text: Optional[str] = None\n",
    "    image: Optional[str] = None          # URL or base64\n",
    "    file: Optional[str] = None           # File path or URL\n",
    "    audio: Optional[Union[str, dict]] = None\n",
    "    video: Optional[Union[str, list]] = None\n",
    "```\n",
    "\n",
    "### **Important Rule**: Exactly ONE field must be provided\n",
    "\n",
    "The validator (lines 95-111) ensures mutual exclusivity:\n",
    "```python\n",
    "if provided_fields != 1:\n",
    "    raise ValueError(\"Exactly one of 'text', 'image', 'file', 'audio', or 'video' must be provided.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_agent.llm.schema import ContentItem\n",
    "\n",
    "# Example 1: Text ContentItem\n",
    "text_item = ContentItem(text='Hello, world!')\n",
    "print(f\"Text item: {text_item}\")\n",
    "print(f\"Type: {text_item.type}\")\n",
    "print(f\"Value: {text_item.value}\")\n",
    "\n",
    "# Example 2: Image ContentItem (URL)\n",
    "image_item = ContentItem(\n",
    "    image='https://example.com/image.jpg'\n",
    ")\n",
    "print(f\"\\nImage item: {image_item}\")\n",
    "print(f\"Type: {image_item.type}\")\n",
    "print(f\"Value: {image_item.value}\")\n",
    "\n",
    "# Example 3: File ContentItem\n",
    "file_item = ContentItem(\n",
    "    file='/path/to/document.pdf'\n",
    ")\n",
    "print(f\"\\nFile item: {file_item}\")\n",
    "\n",
    "# This would FAIL (can't have both text and image):\n",
    "# bad_item = ContentItem(text='Hello', image='image.jpg')  # ValueError!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful ContentItem Methods:\n",
    "\n",
    "```python\n",
    "item.type          # Returns 'text', 'image', 'file', 'audio', or 'video'\n",
    "item.value         # Returns the actual value (string or dict)\n",
    "item.get_type_and_value()  # Returns tuple (type, value)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate methods\n",
    "item = ContentItem(text='Sample text')\n",
    "\n",
    "print(f\"Type property: {item.type}\")\n",
    "print(f\"Value property: {item.value}\")\n",
    "print(f\"Type and value method: {item.get_type_and_value()}\")\n",
    "\n",
    "# Practical usage: checking content type\n",
    "def process_content(item: ContentItem):\n",
    "    \"\"\"Process different content types\"\"\"\n",
    "    if item.type == 'text':\n",
    "        return f\"Processing text: {item.value[:50]}...\"\n",
    "    elif item.type == 'image':\n",
    "        return f\"Processing image from: {item.value}\"\n",
    "    elif item.type == 'file':\n",
    "        return f\"Processing file: {item.value}\"\n",
    "    else:\n",
    "        return f\"Processing {item.type}\"\n",
    "\n",
    "# Test with different types\n",
    "text_content = ContentItem(text='This is a long piece of text that needs processing')\n",
    "image_content = ContentItem(image='https://example.com/photo.jpg')\n",
    "\n",
    "print(f\"\\n{process_content(text_content)}\")\n",
    "print(process_content(image_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Multimodal Messages - Text + Images\n",
    "\n",
    "### When content is a List[ContentItem]:\n",
    "\n",
    "For messages that combine text and images (like vision models), `content` becomes a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multimodal message (text + image)\n",
    "multimodal_msg = Message(\n",
    "    role='user',\n",
    "    content=[\n",
    "        ContentItem(text='What is in this image?'),\n",
    "        ContentItem(image='https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-VL/demo_small.jpg')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Multimodal Message:\")\n",
    "print(f\"Role: {multimodal_msg.role}\")\n",
    "print(f\"Content type: {type(multimodal_msg.content)}\")\n",
    "print(f\"Number of items: {len(multimodal_msg.content)}\")\n",
    "\n",
    "# Iterate through content items\n",
    "for i, item in enumerate(multimodal_msg.content):\n",
    "    print(f\"\\nItem {i}:\")\n",
    "    print(f\"  Type: {item.type}\")\n",
    "    print(f\"  Value: {item.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with a Vision Model (if available):\n",
    "\n",
    "**Note**: This requires a vision-language model like Qwen-VL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with Qwen-VL (uncomment if you have access)\n",
    "from qwen_agent.agents import Assistant\n",
    "\n",
    "# Configure for vision model\n",
    "vl_cfg = {\n",
    "    'model': 'qwen-vl-max',  # Vision-language model\n",
    "    'model_type': 'qwenvl_dashscope'\n",
    "}\n",
    "\n",
    "# Create vision agent\n",
    "# Uncomment to test (requires DashScope access to VL models):\n",
    "# vision_bot = Assistant(llm=vl_cfg)\n",
    "\n",
    "# Create multimodal message\n",
    "# messages = [\n",
    "#     Message(\n",
    "#         role='user',\n",
    "#         content=[\n",
    "#             ContentItem(text='Describe this image in detail'),\n",
    "#             ContentItem(image='https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-VL/demo_small.jpg')\n",
    "#         ]\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# Get response\n",
    "# response = vision_bot.run_nonstream(messages=messages)\n",
    "# for msg in response:\n",
    "#     if msg['role'] == 'assistant':\n",
    "#         print(msg['content'])\n",
    "\n",
    "print(\"Vision model example code ready (commented out).\")\n",
    "print(\"Uncomment to test if you have access to qwen-vl-max.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: The `reasoning_content` Field\n",
    "\n",
    "### What is reasoning_content?\n",
    "\n",
    "Advanced reasoning models (like QwQ-32B) show their \"thinking process\" separately from the final answer.\n",
    "\n",
    "```python\n",
    "class Message:\n",
    "    content: str                      # Final answer\n",
    "    reasoning_content: Optional[str]  # Thinking process\n",
    "```\n",
    "\n",
    "### Example Response Structure:\n",
    "\n",
    "```\n",
    "Message(\n",
    "    role='assistant',\n",
    "    reasoning_content='Let me think... First I need to...',\n",
    "    content='The answer is 42.'\n",
    ")\n",
    "```\n",
    "\n",
    "### Visual Representation:\n",
    "\n",
    "```\n",
    "User: \"Solve 2x + 5 = 15\"\n",
    "\n",
    "Agent:\n",
    "  reasoning_content: \"I need to isolate x.\n",
    "                      First, subtract 5 from both sides: 2x = 10\n",
    "                      Then divide by 2: x = 5\"\n",
    "  \n",
    "  content: \"x = 5\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a reasoning model response\n",
    "reasoning_msg = Message(\n",
    "    role='assistant',\n",
    "    reasoning_content=\"Let me analyze this step by step:\\n1. The question asks about France\\n2. France is in Europe\\n3. The capital is Paris\",\n",
    "    content='The capital of France is Paris.'\n",
    ")\n",
    "\n",
    "print(\"Reasoning Model Response:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nðŸ¤” Thinking Process:\\n{reasoning_msg.reasoning_content}\")\n",
    "print(f\"\\nðŸ’¡ Final Answer:\\n{reasoning_msg.content}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if reasoning content exists\n",
    "if reasoning_msg.get('reasoning_content'):\n",
    "    print(\"\\nâœ… This message includes reasoning!\")\n",
    "else:\n",
    "    print(\"\\nâŒ No reasoning content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use reasoning_content:\n",
    "\n",
    "1. **QwQ-32B and other reasoning models**\n",
    "2. **Complex problem-solving** where showing work is valuable\n",
    "3. **Educational contexts** where explanation matters\n",
    "4. **Debugging agent decisions**\n",
    "\n",
    "For normal models (Qwen-Max, etc.), this field is usually `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: The `FunctionCall` Class (Preview)\n",
    "\n",
    "### Source Code Location:\n",
    "`/qwen_agent/llm/schema.py` (lines 69-78)\n",
    "\n",
    "### FunctionCall Definition:\n",
    "\n",
    "```python\n",
    "class FunctionCall(BaseModelCompatibleDict):\n",
    "    name: str        # Tool name to execute\n",
    "    arguments: str   # JSON string of parameters\n",
    "```\n",
    "\n",
    "### When Agents Use Tools:\n",
    "\n",
    "Instead of generating text, the LLM generates a function call:\n",
    "\n",
    "```\n",
    "User: \"What's the weather in Tokyo?\"\n",
    "\n",
    "Agent generates:\n",
    "  Message(\n",
    "      role='assistant',\n",
    "      content='',\n",
    "      function_call=FunctionCall(\n",
    "          name='weather_api',\n",
    "          arguments='{\"location\": \"Tokyo\"}'\n",
    "      )\n",
    "  )\n",
    "```\n",
    "\n",
    "We'll dive deep into this on **Day 6: Function Calling**. For now, just understand the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_agent.llm.schema import FunctionCall\n",
    "import json\n",
    "\n",
    "# Example 1: Simple function call\n",
    "func_call = FunctionCall(\n",
    "    name='get_weather',\n",
    "    arguments='{\"city\": \"Tokyo\", \"units\": \"celsius\"}'\n",
    ")\n",
    "\n",
    "print(\"Function Call:\")\n",
    "print(f\"Name: {func_call.name}\")\n",
    "print(f\"Arguments (string): {func_call.arguments}\")\n",
    "print(f\"Arguments (parsed): {json.loads(func_call.arguments)}\")\n",
    "\n",
    "# Example 2: Message with function call\n",
    "tool_msg = Message(\n",
    "    role='assistant',\n",
    "    content='',  # Often empty when making function call\n",
    "    function_call=func_call\n",
    ")\n",
    "\n",
    "print(f\"\\nMessage with function call:\")\n",
    "print(tool_msg)\n",
    "\n",
    "# Check if message has function call\n",
    "if tool_msg.get('function_call'):\n",
    "    print(f\"\\nâœ… Agent wants to use tool: {tool_msg.function_call.name}\")\n",
    "else:\n",
    "    print(\"\\nâŒ No function call in this message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: The `name` Field\n",
    "\n",
    "### Purpose:\n",
    "The `name` field identifies the speaker in specific contexts:\n",
    "\n",
    "1. **Function messages**: Which tool generated this result\n",
    "2. **Multi-agent systems**: Which agent is speaking\n",
    "3. **Named personas**: For role-playing scenarios\n",
    "\n",
    "### Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Function result with name\n",
    "function_result = Message(\n",
    "    role='function',\n",
    "    name='web_search',\n",
    "    content='{\"results\": [\"Tokyo weather: Sunny, 25Â°C\"]}'\n",
    ")\n",
    "\n",
    "print(\"Function Result:\")\n",
    "print(f\"Role: {function_result.role}\")\n",
    "print(f\"Name (tool): {function_result.name}\")\n",
    "print(f\"Content: {function_result.content}\")\n",
    "\n",
    "# Example 2: Multi-agent conversation (preview for Day 10)\n",
    "agent1_msg = Message(\n",
    "    role='assistant',\n",
    "    name='CodeExpert',\n",
    "    content='I recommend using a list comprehension for efficiency.'\n",
    ")\n",
    "\n",
    "agent2_msg = Message(\n",
    "    role='assistant',\n",
    "    name='SecurityExpert',\n",
    "    content='Make sure to validate all user inputs first.'\n",
    ")\n",
    "\n",
    "print(f\"\\n{agent1_msg.name}: {agent1_msg.content}\")\n",
    "print(f\"{agent2_msg.name}: {agent2_msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Building Complex Conversations\n",
    "\n",
    "### Realistic Conversation Flow:\n",
    "\n",
    "Let's build a conversation that demonstrates various message types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a realistic conversation\n",
    "conversation = [\n",
    "    # 1. System message sets the context\n",
    "    Message(\n",
    "        role='system',\n",
    "        content='You are a helpful data analyst assistant.'\n",
    "    ),\n",
    "    \n",
    "    # 2. User asks a question\n",
    "    Message(\n",
    "        role='user',\n",
    "        content='I need to analyze sales data from Q1 2024.'\n",
    "    ),\n",
    "    \n",
    "    # 3. Assistant asks for clarification\n",
    "    Message(\n",
    "        role='assistant',\n",
    "        content='I can help with that! What specific metrics are you interested in?'\n",
    "    ),\n",
    "    \n",
    "    # 4. User provides more details\n",
    "    Message(\n",
    "        role='user',\n",
    "        content='Total revenue and top 5 products.'\n",
    "    ),\n",
    "    \n",
    "    # 5. Assistant decides to use a tool (simulated)\n",
    "    Message(\n",
    "        role='assistant',\n",
    "        content='',\n",
    "        function_call=FunctionCall(\n",
    "            name='analyze_sales',\n",
    "            arguments='{\"period\": \"Q1 2024\", \"metrics\": [\"revenue\", \"top_products\"]}'\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    # 6. Tool returns results\n",
    "    Message(\n",
    "        role='function',\n",
    "        name='analyze_sales',\n",
    "        content='{\"total_revenue\": 1250000, \"top_products\": [\"ProductA\", \"ProductB\", \"ProductC\", \"ProductD\", \"ProductE\"]}'\n",
    "    ),\n",
    "    \n",
    "    # 7. Assistant presents results\n",
    "    Message(\n",
    "        role='assistant',\n",
    "        content='Based on the Q1 2024 data:\\n- Total Revenue: $1,250,000\\n- Top 5 Products: ProductA, ProductB, ProductC, ProductD, ProductE'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Display the conversation\n",
    "print(\"Complete Conversation Flow:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, msg in enumerate(conversation, 1):\n",
    "    role_emoji = {\n",
    "        'system': 'âš™ï¸',\n",
    "        'user': 'ðŸ‘¤',\n",
    "        'assistant': 'ðŸ¤–',\n",
    "        'function': 'ðŸ”§'\n",
    "    }\n",
    "    \n",
    "    emoji = role_emoji.get(msg.role, 'â“')\n",
    "    print(f\"\\n{i}. {emoji} {msg.role.upper()}\", end='')\n",
    "    \n",
    "    if msg.get('name'):\n",
    "        print(f\" ({msg.name})\", end='')\n",
    "    print(\":\")\n",
    "    \n",
    "    if msg.get('function_call'):\n",
    "        print(f\"   [Calling tool: {msg.function_call.name}]\")\n",
    "        print(f\"   [Arguments: {msg.function_call.arguments}]\")\n",
    "    elif msg.content:\n",
    "        # Indent content\n",
    "        for line in msg.content.split('\\n'):\n",
    "            print(f\"   {line}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11: Message Utilities\n",
    "\n",
    "### Helper Functions for Working with Messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_messages_by_role(messages, role):\n",
    "    \"\"\"Count messages of a specific role\"\"\"\n",
    "    return sum(1 for msg in messages if msg.get('role') == role)\n",
    "\n",
    "def get_last_user_message(messages):\n",
    "    \"\"\"Get the most recent user message\"\"\"\n",
    "    for msg in reversed(messages):\n",
    "        if msg.get('role') == 'user':\n",
    "            return msg\n",
    "    return None\n",
    "\n",
    "def extract_text_content(message):\n",
    "    \"\"\"Extract text from message content (handles both str and List[ContentItem])\"\"\"\n",
    "    content = message.get('content', '')\n",
    "    \n",
    "    if isinstance(content, str):\n",
    "        return content\n",
    "    elif isinstance(content, list):\n",
    "        # Extract text from ContentItems\n",
    "        texts = [item.value for item in content if item.type == 'text']\n",
    "        return ' '.join(texts)\n",
    "    return ''\n",
    "\n",
    "def has_function_call(message):\n",
    "    \"\"\"Check if message contains a function call\"\"\"\n",
    "    return message.get('function_call') is not None\n",
    "\n",
    "def is_multimodal(message):\n",
    "    \"\"\"Check if message contains non-text content\"\"\"\n",
    "    content = message.get('content', '')\n",
    "    if isinstance(content, list):\n",
    "        return any(item.type != 'text' for item in content)\n",
    "    return False\n",
    "\n",
    "# Test the utilities\n",
    "print(\"Message Utilities Demo:\")\n",
    "print(f\"User messages: {count_messages_by_role(conversation, 'user')}\")\n",
    "print(f\"Assistant messages: {count_messages_by_role(conversation, 'assistant')}\")\n",
    "print(f\"Function messages: {count_messages_by_role(conversation, 'function')}\")\n",
    "\n",
    "last_user = get_last_user_message(conversation)\n",
    "if last_user:\n",
    "    print(f\"\\nLast user message: {extract_text_content(last_user)}\")\n",
    "\n",
    "# Check for function calls\n",
    "func_calls = [msg for msg in conversation if has_function_call(msg)]\n",
    "print(f\"\\nMessages with function calls: {len(func_calls)}\")\n",
    "\n",
    "# Create a multimodal message to test\n",
    "mm_msg = Message(\n",
    "    role='user',\n",
    "    content=[\n",
    "        ContentItem(text='Describe this'),\n",
    "        ContentItem(image='image.jpg')\n",
    "    ]\n",
    ")\n",
    "print(f\"Multimodal message: {is_multimodal(mm_msg)}\")\n",
    "print(f\"Text-only message: {is_multimodal(conversation[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12: Working with Real Agents\n",
    "\n",
    "### Sending and Receiving Messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from qwen_agent.agents import Assistant\n\n# Create agent using llm_cfg from cell 4 (Fireworks API)\nbot = Assistant(llm=llm_cfg)\n\n# Build messages using Message objects\nmessages = [\n    Message(\n        role='system',\n        content='You are a concise assistant. Keep responses under 50 words.'\n    ),\n    Message(\n        role='user',\n        content='Explain what a REST API is.'\n    )\n]\n\nprint(\"Sending messages to agent...\\n\")\n\n# Get response (collect all streaming responses)\nresponse = None\nfor resp in bot.run(messages=messages):\n    response = resp\n\n# Examine the response structure\nprint(\"Response Analysis:\")\nprint(f\"Response type: {type(response)}\")\nprint(f\"Number of messages: {len(response)}\")\n\nfor i, msg in enumerate(response):\n    print(f\"\\nMessage {i}:\")\n    print(f\"  Role: {msg.get('role')}\")\n    print(f\"  Content type: {type(msg.get('content'))}\")\n    \n    if msg.get('role') == 'assistant':\n        content = extract_text_content(msg)\n        # Show just the last 200 chars (thinking model may have long responses)\n        if len(content) > 200:\n            print(f\"  Content (excerpt): ...{content[-200:]}\")\n        else:\n            print(f\"  Content: {content}\")\n        print(f\"  Word count: {len(content.split())}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 13: Message Serialization\n",
    "\n",
    "### Converting Messages to/from JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a message\n",
    "msg = Message(\n",
    "    role='user',\n",
    "    content='Hello, world!',\n",
    "    extra={'timestamp': '2024-01-15T10:30:00'}\n",
    ")\n",
    "\n",
    "# Method 1: model_dump() - to dict\n",
    "msg_dict = msg.model_dump()\n",
    "print(\"As dictionary:\")\n",
    "print(msg_dict)\n",
    "\n",
    "# Method 2: model_dump_json() - to JSON string\n",
    "msg_json = msg.model_dump_json()\n",
    "print(\"\\nAs JSON string:\")\n",
    "print(msg_json)\n",
    "\n",
    "# Method 3: Manual JSON serialization\n",
    "msg_json_manual = json.dumps(msg.model_dump(), indent=2)\n",
    "print(\"\\nAs formatted JSON:\")\n",
    "print(msg_json_manual)\n",
    "\n",
    "# Deserialize back to Message\n",
    "loaded_dict = json.loads(msg_json)\n",
    "reconstructed_msg = Message(**loaded_dict)\n",
    "print(\"\\nReconstructed message:\")\n",
    "print(reconstructed_msg)\n",
    "print(f\"Equal to original: {msg.model_dump() == reconstructed_msg.model_dump()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving/Loading Conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a conversation\n",
    "convo = [\n",
    "    Message(role='user', content='Hi there!'),\n",
    "    Message(role='assistant', content='Hello! How can I help?'),\n",
    "    Message(role='user', content='Tell me a joke.'),\n",
    "]\n",
    "\n",
    "# Save to file\n",
    "def save_conversation(messages, filename):\n",
    "    \"\"\"Save conversation to JSON file\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(\n",
    "            [msg.model_dump() for msg in messages],\n",
    "            f,\n",
    "            indent=2\n",
    "        )\n",
    "\n",
    "def load_conversation(filename):\n",
    "    \"\"\"Load conversation from JSON file\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        return [Message(**msg_dict) for msg_dict in data]\n",
    "\n",
    "# Save\n",
    "save_conversation(convo, 'conversation.json')\n",
    "print(\"âœ… Conversation saved to conversation.json\")\n",
    "\n",
    "# Load\n",
    "loaded_convo = load_conversation('conversation.json')\n",
    "print(f\"âœ… Loaded {len(loaded_convo)} messages\")\n",
    "\n",
    "for msg in loaded_convo:\n",
    "    print(f\"  {msg.role}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 14: Practice Exercises\n",
    "\n",
    "### Exercise 1: Create a Multimodal Message\n",
    "Build a message that combines text and an image URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a multimodal message\n",
    "# Requirements:\n",
    "# 1. Use ContentItem for both text and image\n",
    "# 2. Text should ask a question about the image\n",
    "# 3. Image URL can be any valid URL\n",
    "\n",
    "# Your code here:\n",
    "multimodal_exercise = None\n",
    "\n",
    "# Test:\n",
    "# print(multimodal_exercise)\n",
    "# print(f\"Is multimodal: {is_multimodal(multimodal_exercise)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Build a Conversation Parser\n",
    "Create a function that analyzes a conversation and returns statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement conversation_stats()\n",
    "# Should return:\n",
    "# - Total messages\n",
    "# - Messages per role\n",
    "# - Number of function calls\n",
    "# - Average message length\n",
    "# - Has system message?\n",
    "\n",
    "def conversation_stats(messages):\n",
    "    \"\"\"Analyze a conversation\"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test with the conversation we built earlier:\n",
    "# stats = conversation_stats(conversation)\n",
    "# print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Message Filter\n",
    "Filter a conversation to show only specific types of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement message filters\n",
    "\n",
    "def filter_by_role(messages, role):\n",
    "    \"\"\"Return only messages with specific role\"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "def filter_function_calls(messages):\n",
    "    \"\"\"Return only messages with function calls\"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "def filter_multimodal(messages):\n",
    "    \"\"\"Return only multimodal messages\"\"\"\n",
    "    # Your code here\n",
    "    pass\n",
    "\n",
    "# Test:\n",
    "# user_msgs = filter_by_role(conversation, 'user')\n",
    "# print(f\"User messages: {len(user_msgs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 15: Key Takeaways\n",
    "\n",
    "### What You Learned Today:\n",
    "\n",
    "1. **Message Structure**\n",
    "   - `role`: Who is speaking (system/user/assistant/function)\n",
    "   - `content`: What is being said (str or List[ContentItem])\n",
    "   - `reasoning_content`: Thinking process (for reasoning models)\n",
    "   - `name`: Speaker identifier\n",
    "   - `function_call`: Tool invocation data\n",
    "   - `extra`: Additional metadata\n",
    "\n",
    "2. **ContentItem for Multimodal**\n",
    "   - Exactly ONE of: text, image, file, audio, video\n",
    "   - Use `.type` and `.value` properties\n",
    "   - Combine in lists for multimodal messages\n",
    "\n",
    "3. **FunctionCall Structure**\n",
    "   - `name`: Tool to execute\n",
    "   - `arguments`: JSON string parameters\n",
    "   - Enables agent tool use\n",
    "\n",
    "4. **Message Utilities**\n",
    "   - Dict-compatible interface\n",
    "   - Serialization to/from JSON\n",
    "   - Helper functions for analysis\n",
    "\n",
    "### Common Patterns:\n",
    "\n",
    "```python\n",
    "# Pattern 1: Simple text message\n",
    "msg = Message(role='user', content='Hello')\n",
    "\n",
    "# Pattern 2: Multimodal message\n",
    "msg = Message(\n",
    "    role='user',\n",
    "    content=[\n",
    "        ContentItem(text='What is this?'),\n",
    "        ContentItem(image='url')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pattern 3: Function call message\n",
    "msg = Message(\n",
    "    role='assistant',\n",
    "    content='',\n",
    "    function_call=FunctionCall(name='tool', arguments='{}')\n",
    ")\n",
    "\n",
    "# Pattern 4: Function result message\n",
    "msg = Message(\n",
    "    role='function',\n",
    "    name='tool_name',\n",
    "    content='result data'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 16: Next Steps\n",
    "\n",
    "### Tomorrow (Day 3): LLM Integration\n",
    "We'll explore:\n",
    "- BaseChatModel interface\n",
    "- Different model backends (DashScope, vLLM, Ollama)\n",
    "- Generation parameters\n",
    "- Streaming internals\n",
    "- Token management\n",
    "- Direct LLM usage (without agents)\n",
    "\n",
    "### Homework:\n",
    "1. Create a conversation with at least 5 turns\n",
    "2. Build a multimodal message with your own image\n",
    "3. Implement the exercise functions above\n",
    "4. Read the source: `/qwen_agent/llm/schema.py`\n",
    "5. Experiment with reasoning_content (if you have QwQ access)\n",
    "\n",
    "### Resources:\n",
    "- [Schema Source Code](../qwen_agent/llm/schema.py)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/) - Message uses Pydantic\n",
    "- [OpenAI Message Format](https://platform.openai.com/docs/api-reference/chat) - Similar structure\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ‰ Day 2 Complete!\n",
    "\n",
    "You now understand:\n",
    "- âœ… Message structure and fields\n",
    "- âœ… Role types and their purposes\n",
    "- âœ… ContentItem for multimodal content\n",
    "- âœ… FunctionCall basics\n",
    "- âœ… Message serialization and utilities\n",
    "\n",
    "See you tomorrow for Day 3! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}