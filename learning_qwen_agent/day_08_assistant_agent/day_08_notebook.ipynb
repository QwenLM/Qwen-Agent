{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 8: Assistant Agent - Your Production-Ready AI Partner\n\n## Welcome to the Power Tool!\n\nToday you'll master the **Assistant** - the most complete and production-ready agent in Qwen-Agent.\n\n**What you've learned so far:**\n- Day 4: Tools give agents real capabilities\n- Day 5: Custom agents with `_run()` method\n- Day 6: Function calling for tool selection\n- Day 7: Creating custom tools with `@register_tool`\n\n**Today: The Assistant brings it ALL together!**\n\nThe Assistant agent is like hiring a super-capable employee who:\n- ‚úÖ Knows how to use tools automatically\n- ‚úÖ Can read and understand documents (RAG)\n- ‚úÖ Follows your instructions precisely\n- ‚úÖ Handles errors gracefully\n- ‚úÖ Streams responses in real-time\n- ‚úÖ Maintains conversation context\n\n### Today's Journey:\n1. **All initialization parameters** - Master every option\n2. **files parameter magic** - Automatic document knowledge\n3. **System message engineering** - Control agent behavior\n4. **function_list flexibility** - Tools in multiple formats\n5. **Real-world examples** - Customer support, code helper, analyst\n6. **Production patterns** - Error handling, streaming, memory\n\nLet's build production-ready assistants! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Part 1: Setup\n\nSame Fireworks API configuration as previous days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nimport json5\n\nos.environ['FIREWORKS_API_KEY'] = 'fw_3ZSpUnVR78vs38jJtyewjcWk'\n\nllm_cfg = {\n    'model': 'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507',\n    'model_server': 'https://api.fireworks.ai/inference/v1',\n    'api_key': os.environ['FIREWORKS_API_KEY'],\n    'generate_cfg': {'max_tokens': 32768, 'temperature': 0.6}\n}\n\nprint('‚úÖ Fireworks API configured')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Part 2: Assistant Parameters - Complete Reference\n\n### The Full Signature\n\n```python\nAssistant(\n    llm,                    # Required: LLM configuration\n    function_list=None,     # Optional: List of tools\n    name=None,              # Optional: Agent's name\n    description=None,       # Optional: What agent does\n    system_message=None,    # Optional: Behavior instructions\n    files=None              # Optional: Documents for RAG\n)\n```\n\n### Parameter Guide:\n\n| Parameter | Required? | Type | Purpose |\n|-----------|-----------|------|--------|\n| `llm` | ‚úÖ Yes | Dict or BaseChatModel | The AI brain |\n| `function_list` | ‚ùå No | List | Tools the agent can use |\n| `name` | ‚ùå No | String | Agent's identity |\n| `description` | ‚ùå No | String | What the agent does |\n| `system_message` | ‚ùå No | String | Behavior/personality |\n| `files` | ‚ùå No | List[str] | Documents to learn from |\n\nLet's explore each parameter with examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Minimal Assistant (Just LLM)\n\nThe simplest possible assistant - just an LLM, no tools, no files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_agent.agents import Assistant\n\n# Minimal assistant - just LLM\nbasic_bot = Assistant(llm=llm_cfg)\n\n# Test it\nmessages = [{'role': 'user', 'content': 'Explain quantum computing in one sentence'}]\n\nprint(\"User: Explain quantum computing in one sentence\\n\")\nfor response in basic_bot.run(messages):\n    if response:\n        print(f\"Assistant: {response[-1].get('content', '')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Assistant with Name and Description\n\nGiving your assistant an identity helps with logging and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant with identity\nnamed_bot = Assistant(\n    llm=llm_cfg,\n    name='PhysicsExpert',\n    description='Expert in physics and mathematics'\n)\n\nprint(f\"Bot name: {named_bot.name}\")\nprint(f\"Bot description: {named_bot.description}\\n\")\n\n# The name/description are mainly for logging and organization\nmessages = [{'role': 'user', 'content': 'What is entropy?'}]\nfor response in named_bot.run(messages):\n    if response:\n        print(f\"{named_bot.name}: {response[-1].get('content', '')[:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Part 3: System Message Engineering\n\n### What is system_message?\n\nThe `system_message` is like **giving instructions to an employee** on their first day.\n\nIt controls:\n- ‚úÖ Personality and tone\n- ‚úÖ Response format\n- ‚úÖ Expertise and knowledge\n- ‚úÖ Behavior rules\n- ‚úÖ When to use tools\n\nLet's see the power of system messages!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Role-Playing with System Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pirate assistant\npirate_bot = Assistant(\n    llm=llm_cfg,\n    name='CaptainCodebeard',\n    system_message=\"\"\"You are a friendly pirate captain who teaches programming.\nAlways:\n- Talk like a pirate (use 'arr', 'matey', 'ye')\n- Make sailing/ocean analogies\n- Be enthusiastic and encouraging\n- Keep technical accuracy\"\"\"\n)\n\nmessages = [{'role': 'user', 'content': 'Explain what a Python function is'}]\n\nprint(\"üè¥‚Äç‚ò†Ô∏è Pirate Programming Tutor:\\n\")\nfor response in pirate_bot.run(messages):\n    if response:\n        print(response[-1].get('content', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Output Formatting with System Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON output assistant\njson_bot = Assistant(\n    llm=llm_cfg,\n    system_message=\"\"\"You are a data extraction assistant.\nALWAYS respond in this JSON format:\n{\n  \"summary\": \"brief summary\",\n  \"key_points\": [\"point 1\", \"point 2\"],\n  \"confidence\": 0.95\n}\n\nNo other text outside the JSON.\"\"\"\n)\n\nmessages = [{'role': 'user', 'content': 'Summarize the benefits of exercise'}]\n\nprint(\"Structured JSON Output:\\n\")\nfor response in json_bot.run(messages):\n    if response:\n        print(response[-1].get('content', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Expert Persona System Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medical expert (educational purposes only)\nmedical_bot = Assistant(\n    llm=llm_cfg,\n    name='MedicalEducator',\n    system_message=\"\"\"You are a medical educator for students.\n\nGuidelines:\n- Explain medical concepts clearly\n- Use analogies for complex topics\n- Always include disclaimers for health advice\n- Cite general medical knowledge\n- Encourage consulting real doctors\n\nFormat:\n1. Main explanation\n2. Example or analogy\n3. Disclaimer\"\"\"\n)\n\nmessages = [{'role': 'user', 'content': 'How does insulin work?'}]\n\nprint(\"Medical Education Mode:\\n\")\nfor response in medical_bot.run(messages):\n    if response:\n        print(response[-1].get('content', '')[:400] + '...\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Part 4: The files Parameter - Automatic RAG\n\n### What is RAG?\n\n**RAG (Retrieval-Augmented Generation)** means:\n1. Give your agent documents to learn from\n2. When user asks a question, agent finds relevant parts\n3. Agent uses those parts to answer accurately\n\n### How files Works\n\nWhen you provide `files` parameter:\n```python\nAssistant(llm=llm_cfg, files=['document.pdf'])\n```\n\nQwen-Agent automatically:\n1. ‚úÖ Reads the document\n2. ‚úÖ Splits into chunks\n3. ‚úÖ Creates embeddings\n4. ‚úÖ Retrieves relevant chunks for each query\n5. ‚úÖ Augments LLM context\n\n**You get instant document Q&A!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: RAG with Local File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample company policy document\npolicy_content = \"\"\"ACME Corporation Employee Handbook\n\n1. VACATION POLICY\nEmployees receive 20 vacation days per year.\nVacation must be requested 2 weeks in advance.\nUnused vacation carries over up to 5 days.\n\n2. REMOTE WORK POLICY\nEmployees may work remotely 3 days per week.\nCore hours (10 AM - 3 PM) must be available online.\nMonthly in-office meetings are mandatory.\n\n3. SICK LEAVE\nUnlimited sick leave with doctor's note.\nFirst 3 days don't require documentation.\nNotify manager by 9 AM.\n\n4. PROFESSIONAL DEVELOPMENT\n$2000 annual budget for courses/conferences.\nMust be job-related and pre-approved.\nTime off granted for attending.\n\n5. EQUIPMENT\nCompany provides laptop and monitor.\nHome office stipend: $500 annually.\nIT support available 24/7.\n\"\"\"\n\n# Save to file\nwith open('acme_policy.txt', 'w') as f:\n    f.write(policy_content)\n\nprint(\"‚úÖ Created company policy document\")\n\n# Create RAG-enabled assistant\nhr_assistant = Assistant(\n    llm=llm_cfg,\n    name='HR Assistant',\n    description='Helps employees understand company policies',\n    system_message=\"\"\"You are a friendly HR assistant.\n\nGuidelines:\n- Answer based on the company policy document\n- Be specific and cite policy sections\n- If information isn't in the document, say so\n- Be helpful and friendly\"\"\",\n    files=[os.path.abspath('acme_policy.txt')]\n)\n\nprint(\"‚úÖ Created HR Assistant with RAG\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the RAG assistant with various questions\ntest_questions = [\n    \"How many vacation days do I get?\",\n    \"What's the remote work policy?\",\n    \"Do I get money for professional development?\",\n    \"What happens if I'm sick?\"\n]\n\nfor question in test_questions:\n    print(f\"\\n{'='*60}\")\n    print(f\"User: {question}\")\n    print(f\"{'='*60}\\n\")\n    \n    messages = [{'role': 'user', 'content': question}]\n    \n    for response in hr_assistant.run(messages):\n        if response:\n            answer = response[-1].get('content', '')\n            print(f\"HR Assistant: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: RAG with URL (Arxiv Paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research paper assistant (from official examples)\nresearch_bot = Assistant(\n    llm=llm_cfg,\n    name='Research Assistant',\n    system_message='You help researchers understand academic papers. Be technical but clear.',\n    files=['https://arxiv.org/pdf/1706.03762.pdf']  # Famous \"Attention Is All You Need\" paper\n)\n\n# Ask about the paper\nmessages = [{'role': 'user', 'content': 'What is the main contribution of this paper?'}]\n\nprint(\"Research Assistant (reading Transformer paper):\\n\")\nfor response in research_bot.run(messages):\n    if response:\n        print(response[-1].get('content', '')[:300] + '...\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Handling in Messages\n\nYou can also pass files directly in messages (in addition to or instead of files parameter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant without pre-loaded files\nflexible_bot = Assistant(llm=llm_cfg)\n\n# Pass file in the message itself\nmessages = [{\n    'role': 'user',\n    'content': [\n        {'text': 'What is the vacation policy in this document?'},\n        {'file': os.path.abspath('acme_policy.txt')}\n    ]\n}]\n\nprint(\"File passed in message:\\n\")\nfor response in flexible_bot.run(messages):\n    if response:\n        print(response[-1].get('content', '')[:200] + '...\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Part 5: function_list - Tool Integration\n\n### Multiple Ways to Provide Tools\n\nThe `function_list` parameter accepts:\n1. ‚úÖ String names (built-in tools)\n2. ‚úÖ Tool configuration dicts\n3. ‚úÖ BaseTool instances (custom tools)\n4. ‚úÖ MCP server configs\n5. ‚úÖ Mixed combinations\n\nLet's see each!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 8: String Names (Built-in Tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant with code execution capability\ncode_bot = Assistant(\n    llm=llm_cfg,\n    function_list=['code_interpreter'],  # String name\n    system_message='You are a helpful coding assistant. Use code execution when needed.'\n)\n\nmessages = [{'role': 'user', 'content': 'Calculate the factorial of 15'}]\n\nprint(\"Code execution assistant:\\n\")\nfor response in code_bot.run(messages):\n    for msg in response:\n        if msg.get('function_call'):\n            print(f\"üîß Calling: {msg['function_call']['name']}\\n\")\n        elif msg.get('content'):\n            print(f\"Response: {msg['content']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9: Custom Tool Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_agent.tools.base import BaseTool, register_tool\nimport urllib.parse\n\n# Create custom tool\n@register_tool('weather_api')\nclass WeatherTool(BaseTool):\n    description = 'Get current weather for a city'\n    parameters = [{\n        'name': 'city',\n        'type': 'string',\n        'description': 'City name',\n        'required': True\n    }]\n    \n    def call(self, params, **kwargs):\n        city = json5.loads(params)['city']\n        # Simulated response\n        return json.dumps({'city': city, 'temp': 72, 'condition': 'Sunny'})\n\n# Use custom tool\nweather_bot = Assistant(\n    llm=llm_cfg,\n    function_list=['weather_api'],  # Our custom tool\n    system_message='You are a weather assistant. Always use the weather tool to get current conditions.'\n)\n\nmessages = [{'role': 'user', 'content': 'What\\'s the weather in Tokyo?'}]\n\nprint(\"Weather assistant:\\n\")\nfor response in weather_bot.run(messages):\n    for msg in response:\n        if msg.get('content'):\n            print(msg['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 10: Mixed Tools (Built-in + Custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant with multiple tool types\nmulti_tool_bot = Assistant(\n    llm=llm_cfg,\n    function_list=[\n        'code_interpreter',  # Built-in\n        'weather_api'        # Custom\n    ],\n    system_message='You are a versatile assistant. Use appropriate tools for each task.'\n)\n\ntest_queries = [\n    \"Calculate 2^100\",\n    \"What's the weather in London?\"\n]\n\nfor query in test_queries:\n    print(f\"\\n{'='*60}\")\n    print(f\"User: {query}\")\n    print(f\"{'='*60}\\n\")\n    \n    messages = [{'role': 'user', 'content': query}]\n    \n    for response in multi_tool_bot.run(messages):\n        for msg in response:\n            if msg.get('function_call'):\n                print(f\"‚Üí Using tool: {msg['function_call']['name']}\")\n            elif msg.get('content'):\n                print(f\"‚Üí {msg['content'][:150]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Part 6: Real-World Example - Customer Support Bot\n\nLet's build a production-ready customer support assistant that combines everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create product FAQ document\nfaq_content = \"\"\"Product FAQ - SmartWatch Pro\n\nQ: What is the battery life?\nA: Up to 7 days with normal use, 3 days with GPS active.\n\nQ: Is it waterproof?\nA: Yes, rated IP68. Safe for swimming and showering.\n\nQ: What phones does it work with?\nA: Compatible with iPhone (iOS 13+) and Android (8.0+).\n\nQ: How do I charge it?\nA: Use included magnetic charging cable. Full charge takes 2 hours.\n\nQ: Can I make calls?\nA: Yes, with built-in speaker and microphone via Bluetooth.\n\nQ: What's the return policy?\nA: 30-day money-back guarantee. Free returns.\n\nQ: What sensors does it have?\nA: Heart rate, SpO2, accelerometer, gyroscope, GPS, altimeter.\n\"\"\"\n\nwith open('product_faq.txt', 'w') as f:\n    f.write(faq_content)\n\nprint(\"‚úÖ Created product FAQ\")\n\n# Build comprehensive support bot\nsupport_bot = Assistant(\n    llm=llm_cfg,\n    name='SmartWatch Support',\n    description='Customer support for SmartWatch Pro products',\n    system_message=\"\"\"You are a friendly and professional customer support agent for SmartWatch Pro.\n\nGuidelines:\n1. Always be polite and empathetic\n2. Use the FAQ document to answer questions\n3. If you need to calculate (discounts, dates), use code_interpreter\n4. If answer isn't in FAQ, be honest and offer to escalate\n5. Keep responses concise but complete\n6. End with \"Is there anything else I can help with?\"\n\nTone: Professional yet warm and friendly.\"\"\",\n    function_list=['code_interpreter'],\n    files=[os.path.abspath('product_faq.txt')]\n)\n\nprint(\"‚úÖ Created SmartWatch Support Bot\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with customer scenarios\ncustomer_questions = [\n    \"Is the watch waterproof?\",\n    \"I want to buy 3 watches at $299 each. Can you calculate my total with 15% discount?\",\n    \"What's the return policy?\",\n    \"Does it work with my Samsung Galaxy?\"\n]\n\nfor question in customer_questions:\n    print(\"\\n\" + \"=\"*70)\n    print(f\"Customer: {question}\")\n    print(\"=\"*70)\n    \n    messages = [{'role': 'user', 'content': question}]\n    \n    for response in support_bot.run(messages):\n        for msg in response:\n            if msg.get('function_call'):\n                print(f\"\\n[Using tool: {msg['function_call']['name']}]\")\n            elif msg.get('content'):\n                print(f\"\\nSupport: {msg['content']}\")\n    \n    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Part 7: Production Patterns\n\n### Pattern 1: Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_assistant_call(bot, user_message, max_retries=3):\n    \"\"\"Call assistant with error handling and retries\"\"\"\n    messages = [{'role': 'user', 'content': user_message}]\n    \n    for attempt in range(max_retries):\n        try:\n            responses = []\n            for response in bot.run(messages):\n                responses = response\n            return responses\n        except Exception as e:\n            print(f\"Attempt {attempt + 1} failed: {e}\")\n            if attempt == max_retries - 1:\n                return [{'role': 'assistant', 'content': f'Error: {str(e)}'}]\n    \n    return [{'role': 'assistant', 'content': 'Service unavailable'}]\n\n# Test error handling\nresult = safe_assistant_call(support_bot, \"What's the battery life?\")\nprint(f\"Result: {result[-1].get('content', '')[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 2: Conversation Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-turn conversation with memory\nconversation_history = []\n\nbot = Assistant(\n    llm=llm_cfg,\n    system_message='You are a helpful assistant. Remember context from previous messages.'\n)\n\n# Simulate multi-turn conversation\nturns = [\n    \"My name is Alice\",\n    \"I'm interested in learning Python\",\n    \"What was my name again?\"\n]\n\nfor turn in turns:\n    print(f\"\\nUser: {turn}\")\n    conversation_history.append({'role': 'user', 'content': turn})\n    \n    for response in bot.run(conversation_history):\n        if response:\n            assistant_msg = response[-1]\n            print(f\"Assistant: {assistant_msg.get('content', '')}\")\n            conversation_history.extend(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern 3: Streaming with typewriter_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_agent.utils.output_beautify import typewriter_print\n\nbot = Assistant(llm=llm_cfg)\nmessages = [{'role': 'user', 'content': 'Write a haiku about coding'}]\n\nprint(\"\\nStreaming response:\\n\")\nresponse_text = ''\nfor response in bot.run(messages):\n    response_text = typewriter_print(response, response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Part 8: Practice Exercises\n\n### Exercise 1: Build a Code Review Bot\n\nCreate an assistant that:\n- Reviews Python code for best practices\n- Uses code_interpreter to test code\n- Provides constructive feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create code review assistant\n# review_bot = Assistant(...)\n# Test with some sample code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Technical Writer Assistant\n\nCreate an assistant that:\n- Reads a code file\n- Generates documentation\n- Follows markdown format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create technical writing assistant\n# writer_bot = Assistant(...)\n# Test with a sample code file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Multi-Tool Data Analyst\n\nCreate an assistant that:\n- Uses code_interpreter for calculations\n- Reads CSV/data files\n- Provides insights and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create data analyst assistant\n# analyst_bot = Assistant(...)\n# Test with sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## Summary: What You Learned\n\n### Core Concepts Mastered\n\n‚úÖ **All Assistant parameters**\n- `llm`: The AI brain\n- `function_list`: Tools for capabilities\n- `name` & `description`: Identity\n- `system_message`: Behavior control\n- `files`: Automatic RAG\n\n‚úÖ **System message engineering**\n- Role-playing and personality\n- Output formatting\n- Expert personas\n- Behavior rules\n\n‚úÖ **files parameter (RAG)**\n- Automatic document processing\n- Works with URLs and local files\n- Instant Q&A over documents\n- File-in-message pattern\n\n‚úÖ **function_list flexibility**\n- String names for built-in tools\n- Custom tool instances\n- Mixed configurations\n- MCP integration (Day 10)\n\n‚úÖ **Production patterns**\n- Error handling with retries\n- Conversation memory\n- Streaming responses\n- Multi-turn interactions\n\n### Real-World Applications\n\n1. **Customer Support** - FAQ + calculations + friendly tone\n2. **HR Assistant** - Policy documents + specific citations\n3. **Research Assistant** - Academic papers + technical explanations\n4. **Code Helper** - Code execution + best practices\n5. **Data Analyst** - File processing + insights\n\n### Key Takeaways\n\n1. **Assistant is production-ready** - Handles tools, files, errors automatically\n2. **System messages are powerful** - Control personality, format, behavior\n3. **files parameter = instant RAG** - No manual setup needed\n4. **Mix and match tools** - Built-in + custom + MCP\n5. **Conversation memory matters** - Maintain context for better UX\n\n---\n\n## What's Next?\n\n**Tomorrow (Day 9): RAG Systems Deep Dive**\n\nYou'll learn:\n- How RAG actually works under the hood\n- ParallelDocQA for advanced document Q&A\n- Chunking strategies and optimization\n- When to use Assistant vs specialized RAG agents\n- Performance tuning and scaling\n\n---\n\n**Congratulations! üéâ**\n\nYou've mastered the Assistant agent - the most versatile tool in Qwen-Agent!\n\nYou can now build production-ready AI assistants that:\n- Use tools intelligently\n- Learn from documents\n- Follow your instructions\n- Handle errors gracefully\n- Maintain conversations\n\n**You're ready for advanced topics!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}