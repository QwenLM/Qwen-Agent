{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 9: RAG Systems\n\n## Deep Dive into Document Intelligence\n\nToday: Master RAG (Retrieval-Augmented Generation)!\n\n### Topics:\n1. RAG workflow explained\n2. Chunking strategies\n3. ParallelDocQA for long documents\n4. Performance optimization\n5. When to use Assistant vs ParallelDocQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nos.environ['FIREWORKS_API_KEY'] = 'fw_3ZTLPrnEtuscTUPYy3sYx3ag'\nllm_cfg = {'model': 'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507', 'model_server': 'https://api.fireworks.ai/inference/v1', 'api_key': os.environ['FIREWORKS_API_KEY'], 'generate_cfg': {'max_tokens': 32768}}\nprint('\u2705 Configured')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAG Workflow\n\n1. **Ingestion**: Read documents\n2. **Chunking**: Split into manageable pieces\n3. **Embedding**: Convert text to vectors\n4. **Storage**: Save in vector database\n5. **Retrieval**: Find relevant chunks for query\n6. **Augmentation**: Add chunks to LLM context\n7. **Generation**: LLM generates answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from qwen_agent.agents import Assistant\n\nwith open('tech_doc.txt', 'w') as f:\n    f.write('RAG improves LLM accuracy by providing relevant context from documents. Chunk size: 500-1000 tokens optimal.')\n\nrag_bot = Assistant(llm=llm_cfg, files=[os.path.abspath('tech_doc.txt')])\nmessages = [{'role': 'user', 'content': 'What is optimal chunk size?'}]\nfor r in rag_bot.run(messages): print(r[-1].get('content',''))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ParallelDocQA\n\nFor very long documents (100+ pages):\n```python\nfrom qwen_agent.agents.doc_qa import ParallelDocQA\nbot = ParallelDocQA(llm={'model': 'qwen-plus-latest'})\n```\n\nAdvantages:\n- Processes documents in parallel\n- Better for multi-document queries\n- Optimized retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n\n\u2705 RAG workflow (7 steps)\n\u2705 Assistant with files (easy RAG)\n\u2705 ParallelDocQA (advanced)\n\u2705 Chunking strategies\n\u2705 Performance tips\n\n**Tomorrow**: Multi-Agent Systems!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}