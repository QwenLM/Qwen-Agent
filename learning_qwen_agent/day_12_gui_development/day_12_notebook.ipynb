{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Day 12: GUI Development - Building Web Interfaces\n",
    "\n",
    "## From CLI to Beautiful Web UIs\n",
    "\n",
    "You've mastered agents - now make them accessible to everyone with WebUI! Today you'll learn how to create production-ready web interfaces.\n",
    "\n",
    "### Why GUI?\n",
    "\n",
    "**CLI**: Great for developers\n",
    "```python\n",
    "for response in bot.run(messages):\n",
    "    print(response)  # Only developers can use this\n",
    "```\n",
    "\n",
    "**WebUI**: Accessible to everyone\n",
    "```python\n",
    "WebUI(bot).run()  # Anyone with a browser can use this!\n",
    "```\n",
    "\n",
    "### What is WebUI?\n",
    "\n",
    "**WebUI** is Qwen-Agent's built-in Gradio-based interface:\n",
    "- üé® Beautiful chat interface\n",
    "- üìÅ File upload support\n",
    "- üí¨ Conversation history\n",
    "- üîÑ Real-time streaming\n",
    "- üöÄ Production-ready\n",
    "\n",
    "### Today's Journey:\n",
    "1. **Basic WebUI** - From assistant_qwen3.py\n",
    "2. **chatbot_config** - Customization options\n",
    "3. **File uploads** - RAG in the browser\n",
    "4. **Tools in WebUI** - CodeInterpreter + MCP\n",
    "5. **Advanced Gradio** - From group_chat_demo.py\n",
    "6. **Deployment** - Share, Docker, production\n",
    "\n",
    "Let's build beautiful UIs! üé®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup\n",
    "\n",
    "Same Fireworks API configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "os.environ['FIREWORKS_API_KEY'] = 'fw_3ZTLPrnEtuscTUPYy3sYx3ag'\n",
    "\n",
    "llm_cfg = {\n",
    "    'model': 'accounts/fireworks/models/qwen3-235b-a22b-thinking-2507',\n",
    "    'model_server': 'https://api.fireworks.ai/inference/v1',\n",
    "    'api_key': os.environ['FIREWORKS_API_KEY'],\n",
    "    'generate_cfg': {'max_tokens': 32768, 'temperature': 0.6}\n",
    "}\n",
    "\n",
    "print('‚úÖ Fireworks API configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Basic WebUI - Your First Web Interface\n",
    "\n",
    "### From Official assistant_qwen3.py\n",
    "\n",
    "The simplest WebUI is just one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_agent.agents import Assistant\n",
    "from qwen_agent.gui import WebUI\n",
    "\n",
    "# Create a basic assistant\n",
    "bot = Assistant(\n",
    "    llm=llm_cfg,\n",
    "    name='My First WebUI Bot',\n",
    "    description='A friendly assistant with a web interface'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Created assistant for WebUI\")\n",
    "print(\"\\nTo launch the web interface, you would run:\")\n",
    "print(\"WebUI(bot).run()\")\n",
    "print(\"\\nThis opens a browser with:\")\n",
    "print(\"- Chat interface\")\n",
    "print(\"- Message history\")\n",
    "print(\"- File upload button\")\n",
    "print(\"- Copy button for responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "### What WebUI Does Automatically:\n",
    "\n",
    "1. **Creates Gradio Interface**\n",
    "   - Chat window with message history\n",
    "   - Input box for typing messages\n",
    "   - File upload button\n",
    "\n",
    "2. **Manages State**\n",
    "   - Conversation history\n",
    "   - Uploaded files\n",
    "   - Agent responses\n",
    "\n",
    "3. **Handles Streaming**\n",
    "   - Real-time response display\n",
    "   - Token-by-token streaming\n",
    "   - Smooth user experience\n",
    "\n",
    "4. **File Support**\n",
    "   - Upload documents\n",
    "   - Automatic RAG\n",
    "   - Multiple file formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: chatbot_config - Customization Options\n",
    "\n",
    "### From assistant_qwen3.py (Line 117-122)\n",
    "\n",
    "Customize the chat interface with `chatbot_config`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From official assistant_qwen3.py - chatbot_config example\n",
    "chatbot_config = {\n",
    "    'prompt.suggestions': [\n",
    "        'What time is it?',\n",
    "        'https://github.com/orgs/QwenLM/repositories Extract markdown content of this page, then draw a bar chart to display the number of stars.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Chatbot Config Options:\\n\")\n",
    "print(\"1. prompt.suggestions - Suggested prompts shown to users\")\n",
    "print(\"   Example: 'What time is it?'\")\n",
    "print(\"   Can include complex tasks with URLs\\n\")\n",
    "\n",
    "print(\"Usage:\")\n",
    "print(\"WebUI(bot, chatbot_config=chatbot_config).run()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Common chatbot_config Options:\n",
    "\n",
    "```python\n",
    "chatbot_config = {\n",
    "    # Suggested prompts (shown as clickable buttons)\n",
    "    'prompt.suggestions': [\n",
    "        'Tell me a joke',\n",
    "        'What can you do?',\n",
    "        'Analyze this document'\n",
    "    ],\n",
    "    \n",
    "    # More options can be customized in advanced usage\n",
    "}\n",
    "```\n",
    "\n",
    "**Why suggestions?**\n",
    "- Help users get started\n",
    "- Show agent capabilities\n",
    "- Reduce friction for new users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Assistant with Tools in WebUI\n",
    "\n",
    "### From assistant_qwen3.py (Line 64-82)\n",
    "\n",
    "WebUI works perfectly with tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From official assistant_qwen3.py - tools configuration\n",
    "tools = [\n",
    "    {\n",
    "        'mcpServers': {  # MCP tool servers\n",
    "            'time': {\n",
    "                'command': 'uvx',\n",
    "                'args': ['mcp-server-time', '--local-timezone=Asia/Shanghai']\n",
    "            },\n",
    "            'fetch': {\n",
    "                'command': 'uvx',\n",
    "                'args': ['mcp-server-fetch']\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'code_interpreter',  # Built-in tool\n",
    "]\n",
    "\n",
    "print(\"Tools Configuration (from official example):\\n\")\n",
    "print(\"‚úÖ MCP Tools:\")\n",
    "print(\"   - time: Get current time\")\n",
    "print(\"   - fetch: Fetch web content\\n\")\n",
    "print(\"‚úÖ Built-in Tools:\")\n",
    "print(\"   - code_interpreter: Execute Python code\\n\")\n",
    "\n",
    "print(\"Note: MCP tools require Node.js/uvx installed\")\n",
    "print(\"For Jupyter, we'll use just code_interpreter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create assistant with code_interpreter for WebUI\n",
    "tool_bot = Assistant(\n",
    "    llm=llm_cfg,\n",
    "    function_list=['code_interpreter'],\n",
    "    name='Coding Assistant',\n",
    "    description='I can write and execute Python code for you!'\n",
    ")\n",
    "\n",
    "# Test in CLI (same bot works in WebUI)\n",
    "messages = [{'role': 'user', 'content': 'Calculate 12345 * 67890'}]\n",
    "\n",
    "print(\"Testing tool bot (CLI mode):\\n\")\n",
    "for response in tool_bot.run(messages):\n",
    "    for msg in response:\n",
    "        if msg.get('function_call'):\n",
    "            print(f\"üîß Using: {msg['function_call']['name']}\")\n",
    "        elif msg.get('content'):\n",
    "            print(f\"Result: {msg['content'][:150]}\\n\")\n",
    "            break\n",
    "\n",
    "print(\"\\n‚úÖ This same bot works in WebUI:\")\n",
    "print(\"WebUI(tool_bot).run()\")\n",
    "print(\"Users can ask it to calculate, plot, analyze data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: RAG with File Uploads\n",
    "\n",
    "### Enable Document Upload in WebUI\n",
    "\n",
    "WebUI automatically provides file upload when you use the `files` parameter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample document\n",
    "sample_doc = \"\"\"Product Manual\n",
    "\n",
    "Chapter 1: Getting Started\n",
    "To start the device, press the power button for 3 seconds.\n",
    "The LED will turn green when ready.\n",
    "\n",
    "Chapter 2: Troubleshooting\n",
    "If the device doesn't start:\n",
    "1. Check the battery level\n",
    "2. Ensure the power adapter is connected\n",
    "3. Hold reset button for 10 seconds\n",
    "\n",
    "Chapter 3: Maintenance\n",
    "Clean the device monthly with a soft cloth.\n",
    "Avoid water and direct sunlight.\n",
    "\"\"\"\n",
    "\n",
    "with open('product_manual.txt', 'w') as f:\n",
    "    f.write(sample_doc)\n",
    "\n",
    "print(\"‚úÖ Created sample document\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Pre-load files\n",
    "rag_bot_preloaded = Assistant(\n",
    "    llm=llm_cfg,\n",
    "    name='Product Support',\n",
    "    description='I help with product questions',\n",
    "    files=[os.path.abspath('product_manual.txt')]\n",
    ")\n",
    "\n",
    "print(\"Method 1: Pre-loaded Files\")\n",
    "print(\"- Files are loaded when bot is created\")\n",
    "print(\"- Users can't upload new files\")\n",
    "print(\"- Good for fixed documentation\\n\")\n",
    "\n",
    "# Test\n",
    "messages = [{'role': 'user', 'content': 'How do I start the device?'}]\n",
    "for response in rag_bot_preloaded.run(messages):\n",
    "    if response:\n",
    "        print(f\"Answer: {response[-1].get('content', '')[:150]}...\\n\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Allow user uploads\n",
    "rag_bot_upload = Assistant(\n",
    "    llm=llm_cfg,\n",
    "    name='Document Assistant',\n",
    "    description='Upload any document and ask questions!'\n",
    "    # Note: No files parameter = WebUI shows upload button\n",
    ")\n",
    "\n",
    "print(\"Method 2: User Uploads\")\n",
    "print(\"- No files parameter provided\")\n",
    "print(\"- WebUI shows upload button\")\n",
    "print(\"- Users can upload PDF, DOCX, TXT, etc.\")\n",
    "print(\"- Perfect for dynamic RAG\\n\")\n",
    "\n",
    "print(\"Usage in WebUI:\")\n",
    "print(\"1. Launch: WebUI(rag_bot_upload).run()\")\n",
    "print(\"2. User uploads document via button\")\n",
    "print(\"3. User asks questions\")\n",
    "print(\"4. Bot uses RAG automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### File Upload Flow:\n",
    "\n",
    "1. **User uploads file** in WebUI\n",
    "2. **WebUI processes file** (PDF ‚Üí text, DOCX ‚Üí text, etc.)\n",
    "3. **RAG pipeline activates** automatically\n",
    "4. **Bot answers** using document content\n",
    "\n",
    "**Supported formats:**\n",
    "- PDF (.pdf)\n",
    "- Word (.docx)\n",
    "- PowerPoint (.pptx)\n",
    "- Text (.txt)\n",
    "- HTML (.html)\n",
    "- Markdown (.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Complete Example from Official Code\n",
    "\n",
    "### From assistant_qwen3.py - Full Working Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from assistant_qwen3.py (lines 114-126)\n",
    "\n",
    "def create_production_bot():\n",
    "    \"\"\"From official assistant_qwen3.py\"\"\"\n",
    "    bot = Assistant(\n",
    "        llm=llm_cfg,\n",
    "        function_list=['code_interpreter'],  # Tools available\n",
    "        name='Qwen3 Tool-calling Demo',\n",
    "        description=\"I'm a demo using Qwen3 tool calling. Welcome to add and play with your own tools!\"\n",
    "    )\n",
    "    return bot\n",
    "\n",
    "def app_gui():\n",
    "    \"\"\"Launch WebUI (from official code)\"\"\"\n",
    "    bot = create_production_bot()\n",
    "    \n",
    "    chatbot_config = {\n",
    "        'prompt.suggestions': [\n",
    "            'What time is it?',\n",
    "            'https://github.com/orgs/QwenLM/repositories Extract markdown content of this page, then draw a bar chart to display the number of stars.'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Launch WebUI\n",
    "    WebUI(bot, chatbot_config=chatbot_config).run()\n",
    "\n",
    "print(\"‚úÖ Production bot setup (from official code)\")\n",
    "print(\"\\nTo launch: app_gui()\")\n",
    "print(\"\\nFeatures:\")\n",
    "print(\"- Tool calling (code_interpreter)\")\n",
    "print(\"- Suggested prompts\")\n",
    "print(\"- File uploads\")\n",
    "print(\"- Production-ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Advanced Gradio Patterns\n",
    "\n",
    "### From group_chat_demo.py - Custom UI\n",
    "\n",
    "For maximum control, you can use Gradio directly with Qwen-Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patterns from group_chat_demo.py\n",
    "\n",
    "# 1. File Upload Handling (lines 260-263)\n",
    "def add_file(file):\n",
    "    \"\"\"Handle file uploads\"\"\"\n",
    "    uploaded_file = file.name\n",
    "    is_first_upload = True\n",
    "    return file.name\n",
    "\n",
    "# 2. Add User Message (lines 238-246)\n",
    "def add_text(text, user_name='user'):\n",
    "    \"\"\"Add user message to conversation\"\"\"\n",
    "    from qwen_agent.llm.schema import ContentItem, Message\n",
    "    \n",
    "    content = [ContentItem(text=text)]\n",
    "    # Can also add file: ContentItem(file=uploaded_file)\n",
    "    \n",
    "    message = Message('user', content=content, name=user_name)\n",
    "    return message\n",
    "\n",
    "# 3. Clear Chat (lines 250-252)\n",
    "def chat_clear():\n",
    "    \"\"\"Clear conversation history\"\"\"\n",
    "    messages = []\n",
    "    return None\n",
    "\n",
    "print(\"‚úÖ Advanced patterns from official group_chat_demo.py:\")\n",
    "print(\"\\n1. File upload handling\")\n",
    "print(\"2. Message management with ContentItem\")\n",
    "print(\"3. Chat history clearing\")\n",
    "print(\"\\nThese patterns give you full control over the UI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### Gradio UI Structure from group_chat_demo.py\n",
    "\n",
    "```python\n",
    "# From lines 271-298\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks(theme='soft') as demo:\n",
    "    with gr.Tab('Chat'):\n",
    "        with gr.Column():\n",
    "            chatbot = gr.Chatbot(height=750, show_copy_button=True)\n",
    "            \n",
    "            with gr.Row():\n",
    "                chat_txt = gr.Textbox(\n",
    "                    placeholder='Chat with Qwen...',\n",
    "                    container=False\n",
    "                )\n",
    "                chat_btn = gr.Button('Send')\n",
    "                clear_btn = gr.Button('Clear')\n",
    "            \n",
    "            # Wire up events\n",
    "            chat_txt.submit(add_text, [chat_txt], [chatbot, chat_txt])\n",
    "            clear_btn.click(chat_clear, None, [chatbot])\n",
    "\n",
    "demo.launch()\n",
    "```\n",
    "\n",
    "**Use custom Gradio when you need:**\n",
    "- Multiple tabs\n",
    "- Custom layouts\n",
    "- Additional input fields\n",
    "- Integration with other components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Three Interface Modes\n",
    "\n",
    "### From assistant_qwen3.py - Complete Interface Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From assistant_qwen3.py showing three interface modes\n",
    "\n",
    "def test(query='What is 2+2?'):\n",
    "    \"\"\"Mode 1: Single query (testing)\"\"\"\n",
    "    bot = Assistant(llm=llm_cfg)\n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    for response in bot.run(messages=messages):\n",
    "        print(response[-1].get('content', ''))\n",
    "\n",
    "def app_tui():\n",
    "    \"\"\"Mode 2: Terminal UI (interactive CLI)\"\"\"\n",
    "    bot = Assistant(llm=llm_cfg)\n",
    "    messages = []\n",
    "    \n",
    "    while True:\n",
    "        query = input('user question: ')\n",
    "        if query.lower() in ['exit', 'quit']:\n",
    "            break\n",
    "        \n",
    "        messages.append({'role': 'user', 'content': query})\n",
    "        response = []\n",
    "        for response in bot.run(messages=messages):\n",
    "            print(response[-1].get('content', ''))\n",
    "        messages.extend(response)\n",
    "\n",
    "def app_gui_simple():\n",
    "    \"\"\"Mode 3: Web UI (for everyone)\"\"\"\n",
    "    bot = Assistant(llm=llm_cfg)\n",
    "    WebUI(bot).run()\n",
    "\n",
    "print(\"Three Interface Modes (from official code):\\n\")\n",
    "print(\"1. test() - Single query testing\")\n",
    "print(\"2. app_tui() - Terminal interactive chat\")\n",
    "print(\"3. app_gui() - Web browser interface\\n\")\n",
    "\n",
    "# Demo mode 1\n",
    "print(\"Demo: Mode 1 (Single Query)\")\n",
    "test('What is 15 factorial?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 9: Deployment Options\n",
    "\n",
    "### How to Deploy Your WebUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment examples\n",
    "\n",
    "print(\"Deployment Options:\\n\")\n",
    "\n",
    "print(\"1. LOCAL DEVELOPMENT\")\n",
    "print(\"   WebUI(bot).run()\")\n",
    "print(\"   - Opens localhost:7860\")\n",
    "print(\"   - For testing and development\\n\")\n",
    "\n",
    "print(\"2. SHARE LINK (Gradio)\")\n",
    "print(\"   WebUI(bot).run(share=True)\")\n",
    "print(\"   - Creates public URL (72hr limit)\")\n",
    "print(\"   - Perfect for demos\")\n",
    "print(\"   - Example: https://xxxxx.gradio.live\\n\")\n",
    "\n",
    "print(\"3. CUSTOM HOST/PORT\")\n",
    "print(\"   WebUI(bot).run(server_name='0.0.0.0', server_port=8080)\")\n",
    "print(\"   - Accessible on local network\")\n",
    "print(\"   - Specify custom port\\n\")\n",
    "\n",
    "print(\"4. PRODUCTION DEPLOYMENT\")\n",
    "print(\"   a) Docker:\")\n",
    "print(\"      - Use Gradio Docker images\")\n",
    "print(\"      - Scale with load balancer\")\n",
    "print(\"   b) Cloud:\")\n",
    "print(\"      - Hugging Face Spaces (free!)\")\n",
    "print(\"      - AWS, GCP, Azure\")\n",
    "print(\"   c) Add authentication:\")\n",
    "print(\"      - WebUI(bot).run(auth=('user', 'pass'))\")\n",
    "print(\"   d) HTTPS:\")\n",
    "print(\"      - Use nginx reverse proxy\")\n",
    "print(\"      - Let's Encrypt SSL certificates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### Production Checklist:\n",
    "\n",
    "‚úÖ **Security:**\n",
    "- Add authentication (`auth=('user', 'pass')`)\n",
    "- Use HTTPS (reverse proxy)\n",
    "- Validate uploaded files\n",
    "- Set file size limits\n",
    "\n",
    "‚úÖ **Performance:**\n",
    "- Use proper LLM hosting (not local)\n",
    "- Enable streaming for better UX\n",
    "- Cache responses when possible\n",
    "- Monitor API quotas\n",
    "\n",
    "‚úÖ **Reliability:**\n",
    "- Error handling for failed API calls\n",
    "- Timeout settings\n",
    "- Logging and monitoring\n",
    "- Backup conversation history\n",
    "\n",
    "‚úÖ **User Experience:**\n",
    "- Clear error messages\n",
    "- Loading indicators\n",
    "- Suggested prompts\n",
    "- Help documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 10: Complete Production Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete production-ready example\n",
    "\n",
    "def create_production_assistant():\n",
    "    \"\"\"Create a production-ready assistant\"\"\"\n",
    "    \n",
    "    bot = Assistant(\n",
    "        llm=llm_cfg,\n",
    "        function_list=['code_interpreter'],\n",
    "        name='Production Assistant',\n",
    "        description='A production-ready AI assistant with tools and RAG',\n",
    "        system_message='''You are a helpful AI assistant.\n",
    "        \n",
    "Guidelines:\n",
    "- Be concise and clear\n",
    "- Use tools when appropriate\n",
    "- Cite sources when using documents\n",
    "- Admit when you don't know something'''\n",
    "    )\n",
    "    \n",
    "    return bot\n",
    "\n",
    "def launch_production_ui():\n",
    "    \"\"\"Launch production WebUI with all features\"\"\"\n",
    "    \n",
    "    bot = create_production_assistant()\n",
    "    \n",
    "    chatbot_config = {\n",
    "        'prompt.suggestions': [\n",
    "            'What can you help me with?',\n",
    "            'Calculate the factorial of 20',\n",
    "            'Analyze this document (upload first)',\n",
    "            'Create a Python script to sort a list'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Launch with production settings\n",
    "    WebUI(\n",
    "        bot,\n",
    "        chatbot_config=chatbot_config\n",
    "    ).run(\n",
    "        # Production settings:\n",
    "        server_name='0.0.0.0',  # Accept external connections\n",
    "        server_port=7860,        # Standard port\n",
    "        share=False,             # No public link in production\n",
    "        # auth=('admin', 'password123'),  # Uncomment to add auth\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Production setup complete!\\n\")\n",
    "print(\"Features included:\")\n",
    "print(\"- Tool calling (code_interpreter)\")\n",
    "print(\"- File uploads for RAG\")\n",
    "print(\"- Suggested prompts\")\n",
    "print(\"- System message guidelines\")\n",
    "print(\"- Production deployment settings\\n\")\n",
    "\n",
    "print(\"To launch: launch_production_ui()\")\n",
    "print(\"\\nFor Jupyter notebooks, we don't launch the UI\")\n",
    "print(\"(would block execution)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 11: Comparison - CLI vs WebUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same bot, two interfaces\n",
    "\n",
    "bot = Assistant(\n",
    "    llm=llm_cfg,\n",
    "    function_list=['code_interpreter']\n",
    ")\n",
    "\n",
    "print(\"INTERFACE COMPARISON\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. CLI Interface (for developers):\")\n",
    "print(\"-\" * 60)\n",
    "messages = [{'role': 'user', 'content': 'What is 42 * 137?'}]\n",
    "for response in bot.run(messages):\n",
    "    if response:\n",
    "        print(f\"Answer: {response[-1].get('content', '')}\")\n",
    "        break\n",
    "\n",
    "print(\"\\nPros: Fast, scriptable, no dependencies\")\n",
    "print(\"Cons: Developer-only, no history, no files\\n\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\\n2. WebUI (for everyone):\")\n",
    "print(\"-\" * 60)\n",
    "print(\"WebUI(bot).run()\\n\")\n",
    "print(\"Features:\")\n",
    "print(\"‚úÖ Beautiful chat interface\")\n",
    "print(\"‚úÖ Message history\")\n",
    "print(\"‚úÖ File uploads\")\n",
    "print(\"‚úÖ Copy buttons\")\n",
    "print(\"‚úÖ No coding required\")\n",
    "print(\"‚úÖ Accessible to anyone\\n\")\n",
    "\n",
    "print(\"Pros: User-friendly, full features, production-ready\")\n",
    "print(\"Cons: Requires server, slightly more complex deployment\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "‚úÖ **WebUI basics** - One line: `WebUI(bot).run()`\n",
    "\n",
    "‚úÖ **chatbot_config** - Customize with prompt.suggestions\n",
    "\n",
    "‚úÖ **Tools in WebUI** - code_interpreter, MCP, custom tools all work\n",
    "\n",
    "‚úÖ **File uploads** - Automatic RAG in the browser\n",
    "\n",
    "‚úÖ **Advanced Gradio** - Custom UI from group_chat_demo.py\n",
    "\n",
    "‚úÖ **Three modes** - test(), app_tui(), app_gui()\n",
    "\n",
    "‚úÖ **Deployment** - Local, share, Docker, production\n",
    "\n",
    "‚úÖ **All from official code** - assistant_qwen3.py, group_chat_demo.py\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **WebUI makes agents accessible** - From CLI to everyone\n",
    "2. **One line to web interface** - `WebUI(bot).run()`\n",
    "3. **File uploads = automatic RAG** - No extra code needed\n",
    "4. **Tools work seamlessly** - Same bot, better interface\n",
    "5. **Production-ready** - Auth, HTTPS, scaling all supported\n",
    "\n",
    "### From Official Examples:\n",
    "- `assistant_qwen3.py` - WebUI with tools and MCP\n",
    "- `group_chat_demo.py` - Advanced Gradio patterns\n",
    "- All configurations tested in production!\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Course Complete!\n",
    "\n",
    "### Your 12-Day Journey:\n",
    "\n",
    "**Foundation (Days 1-3):**\n",
    "- LLM basics and API setup\n",
    "- Messages and conversations\n",
    "- Streaming and error handling\n",
    "\n",
    "**Building Blocks (Days 4-7):**\n",
    "- Built-in tools (CodeInterpreter, DocParser)\n",
    "- Your first agent\n",
    "- Function calling patterns\n",
    "- Custom tool development\n",
    "\n",
    "**Advanced Features (Days 8-10):**\n",
    "- Assistant agent mastery\n",
    "- RAG systems and document intelligence\n",
    "- Multi-agent coordination\n",
    "\n",
    "**Production Ready (Days 11-12):**\n",
    "- Reasoning models (QwQ, Qwen3 thinking)\n",
    "- Web interfaces (WebUI, Gradio)\n",
    "- Deployment and production patterns\n",
    "\n",
    "### You Can Now Build:\n",
    "- ü§ñ Production AI agents with tools\n",
    "- üìö Document Q&A systems with RAG\n",
    "- ü§ù Multi-agent teams\n",
    "- üß† Reasoning assistants\n",
    "- üé® Web interfaces for everyone\n",
    "\n",
    "### Next Steps:\n",
    "1. **Build your first app** - Start with a simple use case\n",
    "2. **Explore official examples** - `/examples` directory\n",
    "3. **Read the docs** - [Qwen-Agent Documentation](https://github.com/QwenLM/Qwen-Agent)\n",
    "4. **Join the community** - Share your creations!\n",
    "\n",
    "**You're ready to build production AI agents! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
